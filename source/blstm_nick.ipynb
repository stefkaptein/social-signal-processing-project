{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, Input, TimeDistributed\n",
    "from model.load_data import train_test_split, train_test_split_LSTM\n",
    "\n",
    "from model.scoring_metrics import get_windiff, get_pk, get_k_kappa\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# I optimize on this, I think?\n",
    "LSTM_units = 20\n",
    "\n",
    "features = ['pause','speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\lolco\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\lolco\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lolco\\anaconda3\\lib\\site-packages (from tensorflow-addons) (22.0)\n",
      "Requirement already satisfied: typeguard in c:\\users\\lolco\\anaconda3\\lib\\site-packages (2.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "!pip install typeguard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "import warnings\n",
    "from typing import Optional\n",
    "from typeguard import typechecked\n",
    "from tensorflow_addons.utils.types import Number\n",
    "\n",
    "class WeightedKappaLoss(tf.keras.losses.Loss):\n",
    "    @typechecked\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            weightage: Optional[str] = \"quadratic\",\n",
    "            name: Optional[str] = \"cohen_kappa_loss\",\n",
    "            epsilon: Optional[Number] = 1e-6,\n",
    "            dtype: Optional[tf.DType] = tf.float32,\n",
    "            reduction: str = tf.keras.losses.Reduction.NONE,\n",
    "    ):\n",
    "        super().__init__(name=name, reduction=reduction)\n",
    "        warnings.warn(\n",
    "            \"The data type for `WeightedKappaLoss` defaults to \"\n",
    "            \"`tf.keras.backend.floatx()`.\"\n",
    "            \"The argument `dtype` will be removed in Addons `0.12`.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "        if weightage not in (\"linear\", \"quadratic\"):\n",
    "            raise ValueError(\"Unknown kappa weighting type.\")\n",
    "\n",
    "        self.weightage = weightage\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon or tf.keras.backend.epsilon()\n",
    "        label_vec = tf.range(num_classes, dtype=tf.keras.backend.floatx())\n",
    "        self.row_label_vec = tf.reshape(label_vec, [1, num_classes])\n",
    "        self.col_label_vec = tf.reshape(label_vec, [num_classes, 1])\n",
    "        col_mat = tf.tile(self.col_label_vec, [1, num_classes])\n",
    "        row_mat = tf.tile(self.row_label_vec, [num_classes, 1])\n",
    "        if weightage == \"linear\":\n",
    "            self.weight_mat = tf.abs(col_mat - row_mat)\n",
    "        else:\n",
    "            self.weight_mat = (col_mat - row_mat) ** 2\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=self.col_label_vec.dtype)\n",
    "        y_pred = tf.cast(y_pred, dtype=self.weight_mat.dtype)\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "        cat_labels = tf.matmul(y_true, self.col_label_vec)\n",
    "        cat_label_mat = tf.tile(cat_labels, [1, self.num_classes])\n",
    "        row_label_mat = tf.tile(self.row_label_vec, [batch_size, 1])\n",
    "        if self.weightage == \"linear\":\n",
    "            weight = tf.abs(cat_label_mat - row_label_mat)\n",
    "        else:\n",
    "            weight = (cat_label_mat - row_label_mat) ** 2\n",
    "        numerator = tf.reduce_sum(weight * y_pred)\n",
    "        label_dist = tf.reduce_sum(y_true, axis=0, keepdims=True)\n",
    "        pred_dist = tf.reduce_sum(y_pred, axis=0, keepdims=True)\n",
    "        w_pred_dist = tf.matmul(self.weight_mat, pred_dist, transpose_b=True)\n",
    "        denominator = tf.reduce_sum(tf.matmul(label_dist, w_pred_dist))\n",
    "        denominator /= tf.cast(batch_size, dtype=denominator.dtype)\n",
    "        loss = tf.math.divide_no_nan(numerator, denominator)\n",
    "        return tf.math.log(loss + self.epsilon)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"weightage\": self.weightage,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47450, 5, 5)\n",
      "(47450, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "from model_trainer_and_tester import read_in_dataset_lstm, test_set_evaluate_multiple_lstm\n",
    "\n",
    "shifts = [-2, -1, 0, 1, 2]\n",
    "\n",
    "n_timesteps = len(shifts)\n",
    "feature_count = len(features)\n",
    "\n",
    "X_train, Y_train = read_in_dataset_lstm(features, shifts, to_read='train')\n",
    "X_test, Y_test = read_in_dataset_lstm(features, shifts, to_read='test')\n",
    "#train_test_split_LSTM(datasets, results_merged_path, n_timesteps, split=train_ratio)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# So, the model should be tanh activations and sigmoid outpiut layers...\n",
    "# I'm going to guess both layers should be blstm... but that's it pretty much I think?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1., ..., 1., 1., 1.])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm going to do sample weight here. For now I'll just set the weight to be... half of the number of weird samples?\n",
    "\n",
    "sample_weight = np.ones(shape=(len(Y_train),))\n",
    "# I'm gonna increase the weight by the inverse of the proportion of weird examples that there are\n",
    "# How I define if there is a weird sample is by summing along the 2D squares to find where there's a 1, and then does a sum of times there's a 1\n",
    "# I'm going to do n_timesteps times the inverse count frequency, because in the final version we only predict with the center value. So to correct for this I add this increase\n",
    "new_weight = n_timesteps*len(Y_train)/np.sum(Y_train, axis=1).sum()\n",
    "\n",
    "# Have to do a flatten() inside because of weird numpy stuff with a length 1 dimension\n",
    "sample_weight[(np.sum(Y_train, axis=1) >= 1).flatten()] = new_weight\n",
    "\n",
    "sample_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x000001B51EBEBAF0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lolco\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 74, in __del__\n",
      "    self.deleter(obj)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 22s 18ms/step - loss: 2.7194 - precision: 0.0134 - recall: 0.0134 - val_loss: 2.2672 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/2\n",
      "668/668 [==============================] - 11s 16ms/step - loss: 2.5806 - precision: 0.0874 - recall: 0.0496 - val_loss: 2.2236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# TODO: Understand how the hell to build a keras model\n",
    "model = Sequential()\n",
    "# For the input number of units, I'll assume that number of timesteps * features is a good enough value\n",
    "model.add(Bidirectional(LSTM(n_timesteps*feature_count, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "model.add(Bidirectional(LSTM(LSTM_units, activation='sigmoid', return_sequences=True, dropout=0.3)))\n",
    "# This last time distributed is super important, it follows the output structure of the paper I've been following closely\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
    "              metrics=[keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')],\n",
    "              weighted_metrics=[])\n",
    "\n",
    "# train the model\n",
    "history=model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=2,\n",
    "                  #class_weight= {0:1, 1:10},\n",
    "                  # sample_weight_mode='temporal',\n",
    "                  sample_weight=sample_weight,\n",
    "                  validation_split=0.1,\n",
    "                  verbose=1\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss': [2.7193782329559326, 2.5805516242980957],\n 'precision': [0.013399504125118256, 0.08741258829832077],\n 'recall': [0.013379584066569805, 0.0495540127158165],\n 'val_loss': [2.267162799835205, 2.2235677242279053],\n 'val_precision': [0.0, 0.0],\n 'val_recall': [0.0, 0.0]}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_results_dict = {}\n",
    "acc_results_dict = {}\n",
    "history.history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model: (1, 16) with Precision: 0.0555555559694767\n",
      "Finished model: (1, 47) with Precision: 0.054054055362939835\n",
      "Finished model: (1, 78) with Precision: 0.0585365854203701\n",
      "Finished model: (1, 109) with Precision: 0.06172839552164078\n",
      "Finished model: (1, 140) with Precision: 0.05314009636640549\n",
      "Finished model: (1, 171) with Precision: 0.06542056053876877\n",
      "Finished model: (1, 202) with Precision: 0.0833333358168602\n",
      "Finished model: (1, 233) with Precision: 0.0517241396009922\n",
      "Finished model: (1, 264) with Precision: 0.05622490122914314\n",
      "Finished model: (1, 295) with Precision: 0.05820105969905853\n",
      "Finished model: (1, 326) with Precision: 0.03097345121204853\n",
      "Finished model: (1, 357) with Precision: 0.04663212597370148\n",
      "Finished model: (1, 388) with Precision: 0.03100775182247162\n",
      "Finished model: (1, 419) with Precision: 0.03846153989434242\n",
      "Finished model: (1, 450) with Precision: 0.10810811072587967\n",
      "Finished model: (1, 481) with Precision: 0.03151862323284149\n",
      "Finished model: (1, 512) with Precision: 0.03186274692416191\n",
      "Finished model: (2, 16) with Precision: 0.0845070406794548\n",
      "Finished model: (2, 47) with Precision: 0.07042253762483597\n",
      "Finished model: (2, 78) with Precision: 0.03305784985423088\n",
      "Finished model: (2, 109) with Precision: 0.04085602983832359\n",
      "Finished model: (2, 140) with Precision: 0.04129793494939804\n",
      "Finished model: (2, 171) with Precision: 0.04800000041723251\n",
      "Finished model: (2, 202) with Precision: 0.06666667014360428\n",
      "Finished model: (2, 233) with Precision: 0.0555555559694767\n",
      "Finished model: (2, 264) with Precision: 0.028037382289767265\n",
      "Finished model: (2, 295) with Precision: 0.07878787815570831\n",
      "Finished model: (2, 326) with Precision: 0.043795619159936905\n",
      "Finished model: (2, 357) with Precision: 0.07352941483259201\n",
      "Finished model: (2, 388) with Precision: 0.019739793613553047\n",
      "Finished model: (2, 419) with Precision: 0.05223880708217621\n",
      "Finished model: (2, 450) with Precision: 0.05343511328101158\n",
      "Finished model: (2, 481) with Precision: 0.030237581580877304\n",
      "Finished model: (2, 512) with Precision: 0.03586497902870178\n",
      "Finished model: (3, 16) with Precision: 0.038235295563936234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-61-2f957824e74b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[1;31m# train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         history = model.fit(X_train, Y_train,\n\u001B[0m\u001B[0;32m     18\u001B[0m                   \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m                   \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1562\u001B[0m                         ):\n\u001B[0;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1564\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1565\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2494\u001B[0m       (graph_function,\n\u001B[0;32m   2495\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2497\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2498\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1860\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1861\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1862\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1863\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1864\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for num_layers in range(1, 5):\n",
    "    # It's 31 per step, because it allows for there to be 16 trials, and for me to not go crazy\n",
    "    for hidden_units in range(16, 513, 31):\n",
    "        #print(\"Starting model: \" + str((num_layers, hidden_units)))\n",
    "        model = Sequential()\n",
    "        # For the input number of units, I'll assume that number of timesteps * features is a good enough value\n",
    "        for _ in range(num_layers):\n",
    "            model.add(Bidirectional(LSTM(hidden_units, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "        model.add(Bidirectional(LSTM(hidden_units, activation='sigmoid', return_sequences=True, dropout=0.3)))\n",
    "        # This last time distributed is super important, it follows the output structure of the paper I've been following closely\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
    "                      metrics=[keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')],\n",
    "                      weighted_metrics=[])\n",
    "\n",
    "        # train the model\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=20,\n",
    "                  #class_weight= {0:1, 1:10},\n",
    "                  # sample_weight_mode='temporal',\n",
    "                  sample_weight=sample_weight,\n",
    "                  validation_split=0.1,\n",
    "                  verbose=0\n",
    "                  )\n",
    "\n",
    "        print(\"Finished model: \" + str((num_layers, hidden_units)) + \" with Precision: \" + str(history.history['val_precision'][-1]))\n",
    "\n",
    "        hist_results_dict[(num_layers, hidden_units)] = history\n",
    "        # It's -1, to take the last accuracy measure obtained\n",
    "        acc_results_dict[(num_layers, hidden_units)] = (history.history['val_precision'][-1], history.history['val_recall'][-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 16): (0.0555555559694767, 0.0364583320915699),\n (1, 47): (0.054054055362939835, 0.03125),\n (1, 78): (0.0585365854203701, 0.0625),\n (1, 109): (0.06172839552164078, 0.02604166604578495),\n (1, 140): (0.05314009636640549, 0.0572916679084301),\n (1, 171): (0.06542056053876877, 0.0364583320915699),\n (1, 202): (0.0833333358168602, 0.02604166604578495),\n (1, 233): (0.0517241396009922, 0.03125),\n (1, 264): (0.05622490122914314, 0.0729166641831398),\n (1, 295): (0.05820105969905853, 0.0572916679084301),\n (1, 326): (0.03097345121204853, 0.0364583320915699),\n (1, 357): (0.04663212597370148, 0.046875),\n (1, 388): (0.03100775182247162, 0.02083333395421505),\n (1, 419): (0.03846153989434242, 0.0677083358168602),\n (1, 450): (0.10810811072587967, 0.02083333395421505),\n (1, 481): (0.03151862323284149, 0.0572916679084301),\n (1, 512): (0.03186274692416191, 0.0677083358168602),\n (2, 16): (0.0845070406794548, 0.03125),\n (2, 47): (0.07042253762483597, 0.02604166604578495),\n (2, 78): (0.03305784985423088, 0.0833333358168602),\n (2, 109): (0.04085602983832359, 0.109375),\n (2, 140): (0.04129793494939804, 0.0729166641831398),\n (2, 171): (0.04800000041723251, 0.0625),\n (2, 202): (0.06666667014360428, 0.02604166604578495),\n (2, 233): (0.0555555559694767, 0.0572916679084301),\n (2, 264): (0.028037382289767265, 0.09375),\n (2, 295): (0.07878787815570831, 0.0677083358168602),\n (2, 326): (0.043795619159936905, 0.03125),\n (2, 357): (0.07352941483259201, 0.02604166604578495),\n (2, 388): (0.019739793613553047, 0.2291666716337204),\n (2, 419): (0.05223880708217621, 0.0364583320915699),\n (2, 450): (0.05343511328101158, 0.0364583320915699),\n (2, 481): (0.030237581580877304, 0.0729166641831398),\n (2, 512): (0.03586497902870178, 0.0885416641831398),\n (3, 16): (0.038235295563936234, 0.0677083358168602)}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "pd.DataFrame(acc_results_dict, columns=acc_results_dict.keys(), index=['Precision', 'Recall']).transpose().to_csv('results_blstm.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483/1483 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[0.00627282],\n        [0.01584293],\n        [0.01336911],\n        [0.02408313],\n        [0.01425999]],\n\n       [[0.00942823],\n        [0.00914664],\n        [0.01536419],\n        [0.0124401 ],\n        [0.00516671]],\n\n       [[0.00379193],\n        [0.00422932],\n        [0.00482995],\n        [0.00295994],\n        [0.00844802]],\n\n       ...,\n\n       [[0.01065987],\n        [0.02366466],\n        [0.00473628],\n        [0.0050675 ],\n        [0.00676939]],\n\n       [[0.02293292],\n        [0.00628696],\n        [0.00566995],\n        [0.00733351],\n        [0.00526068]],\n\n       [[0.00610961],\n        [0.00701646],\n        [0.0087015 ],\n        [0.00562242],\n        [0.00662829]]], dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_y = model.predict(X_train)\n",
    "temp_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's working which is good. It is giving garbage results though."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
