{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, Input, TimeDistributed\n",
    "from model.load_data import train_test_split, train_test_split_LSTM\n",
    "\n",
    "from model.scoring_metrics import get_windiff, get_pk, get_k_kappa\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# I optimize on this, I think?\n",
    "LSTM_units = 20\n",
    "\n",
    "features = ['pause','speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\lolco\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\lolco\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lolco\\anaconda3\\lib\\site-packages (from tensorflow-addons) (22.0)\n",
      "Requirement already satisfied: typeguard in c:\\users\\lolco\\anaconda3\\lib\\site-packages (2.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "!pip install typeguard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "import warnings\n",
    "from typing import Optional\n",
    "from typeguard import typechecked\n",
    "from tensorflow_addons.utils.types import Number\n",
    "\n",
    "class WeightedKappaLoss(tf.keras.losses.Loss):\n",
    "    @typechecked\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            weightage: Optional[str] = \"quadratic\",\n",
    "            name: Optional[str] = \"cohen_kappa_loss\",\n",
    "            epsilon: Optional[Number] = 1e-6,\n",
    "            dtype: Optional[tf.DType] = tf.float32,\n",
    "            reduction: str = tf.keras.losses.Reduction.NONE,\n",
    "    ):\n",
    "        super().__init__(name=name, reduction=reduction)\n",
    "        warnings.warn(\n",
    "            \"The data type for `WeightedKappaLoss` defaults to \"\n",
    "            \"`tf.keras.backend.floatx()`.\"\n",
    "            \"The argument `dtype` will be removed in Addons `0.12`.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "        if weightage not in (\"linear\", \"quadratic\"):\n",
    "            raise ValueError(\"Unknown kappa weighting type.\")\n",
    "\n",
    "        self.weightage = weightage\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon or tf.keras.backend.epsilon()\n",
    "        label_vec = tf.range(num_classes, dtype=tf.keras.backend.floatx())\n",
    "        self.row_label_vec = tf.reshape(label_vec, [1, num_classes])\n",
    "        self.col_label_vec = tf.reshape(label_vec, [num_classes, 1])\n",
    "        col_mat = tf.tile(self.col_label_vec, [1, num_classes])\n",
    "        row_mat = tf.tile(self.row_label_vec, [num_classes, 1])\n",
    "        if weightage == \"linear\":\n",
    "            self.weight_mat = tf.abs(col_mat - row_mat)\n",
    "        else:\n",
    "            self.weight_mat = (col_mat - row_mat) ** 2\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=self.col_label_vec.dtype)\n",
    "        y_pred = tf.cast(y_pred, dtype=self.weight_mat.dtype)\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "        cat_labels = tf.matmul(y_true, self.col_label_vec)\n",
    "        cat_label_mat = tf.tile(cat_labels, [1, self.num_classes])\n",
    "        row_label_mat = tf.tile(self.row_label_vec, [batch_size, 1])\n",
    "        if self.weightage == \"linear\":\n",
    "            weight = tf.abs(cat_label_mat - row_label_mat)\n",
    "        else:\n",
    "            weight = (cat_label_mat - row_label_mat) ** 2\n",
    "        numerator = tf.reduce_sum(weight * y_pred)\n",
    "        label_dist = tf.reduce_sum(y_true, axis=0, keepdims=True)\n",
    "        pred_dist = tf.reduce_sum(y_pred, axis=0, keepdims=True)\n",
    "        w_pred_dist = tf.matmul(self.weight_mat, pred_dist, transpose_b=True)\n",
    "        denominator = tf.reduce_sum(tf.matmul(label_dist, w_pred_dist))\n",
    "        denominator /= tf.cast(batch_size, dtype=denominator.dtype)\n",
    "        loss = tf.math.divide_no_nan(numerator, denominator)\n",
    "        return tf.math.log(loss + self.epsilon)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"weightage\": self.weightage,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47450, 5, 5)\n",
      "(47450, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "from model_trainer_and_tester import read_in_dataset_lstm, test_set_evaluate_multiple_lstm\n",
    "\n",
    "shifts = [-2, -1, 0, 1, 2]\n",
    "\n",
    "n_timesteps = len(shifts)\n",
    "feature_count = len(features)\n",
    "\n",
    "X_train, Y_train = read_in_dataset_lstm(features, shifts, to_read='train')\n",
    "X_test, Y_test = read_in_dataset_lstm(features, shifts, to_read='test')\n",
    "#train_test_split_LSTM(datasets, results_merged_path, n_timesteps, split=train_ratio)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# So, the model should be tanh activations and sigmoid outpiut layers...\n",
    "# I'm going to guess both layers should be blstm... but that's it pretty much I think?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1., ..., 1., 1., 1.])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm going to do sample weight here. For now I'll just set the weight to be... half of the number of weird samples?\n",
    "\n",
    "sample_weight = np.ones(shape=(len(Y_train),))\n",
    "# I'm gonna increase the weight by the number of weird examples that there are\n",
    "# It sums along the 2D squares to find where there's a 1, and then does a sum of times there's a 1\n",
    "new_weight = np.sum(Y_train, axis=1).sum()/2.0\n",
    "\n",
    "# Have to do a flatten() inside because of weird numpy stuff with a length 1 dimension\n",
    "sample_weight[(np.sum(Y_train, axis=1) >= 1).flatten()] = new_weight\n",
    "\n",
    "sample_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "668/668 [==============================] - 19s 16ms/step - loss: 25.9344 - precision_2: 0.0396 - recall_2: 0.0124 - val_loss: 21.6583 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/3\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 24.7127 - precision_2: 0.0766 - recall_2: 0.0530 - val_loss: 20.7949 - val_precision_2: 0.2059 - val_recall_2: 0.0365\n",
      "Epoch 3/3\n",
      "668/668 [==============================] - 8s 13ms/step - loss: 24.4539 - precision_2: 0.0629 - recall_2: 0.0669 - val_loss: 20.2637 - val_precision_2: 0.1064 - val_recall_2: 0.0521\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# TODO: Understand how the hell to build a keras model\n",
    "model = Sequential()\n",
    "# For the input number of units, I'll assume that number of timesteps * features is a good enough value\n",
    "model.add(Bidirectional(LSTM(n_timesteps*feature_count, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "model.add(Bidirectional(LSTM(LSTM_units, activation='sigmoid', return_sequences=True, dropout=0.3)))\n",
    "# This last time distributed is super important, it follows the output structure of the paper I've been following closely\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
    "              metrics=[keras.metrics.Precision(), tf.keras.metrics.Recall()], weighted_metrics=[])\n",
    "\n",
    "# train the model\n",
    "history=model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=3,\n",
    "                  #class_weight= {0:1, 1:10},\n",
    "                  # sample_weight_mode='temporal',\n",
    "                  sample_weight=sample_weight,\n",
    "                  validation_split=0.1,\n",
    "                  verbose=1\n",
    "                  )\n",
    "\n",
    "hist_results_dict = {}\n",
    "acc_results_dict = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 5ms/step\n",
      "71/71 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 5ms/step\n",
      "58/58 [==============================] - 0s 3ms/step\n",
      "55/55 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "58/58 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "55/55 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "66/66 [==============================] - 0s 3ms/step\n",
      "75/75 [==============================] - 0s 3ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Pk       K-k   Windiff\n0   0.554391 -0.202583  0.586282\n1   0.380090 -0.161110  0.380090\n2   0.321965  0.328838  0.360164\n3   0.581089 -0.177916  0.623496\n4   0.466907  0.019918  0.544525\n5   0.234568  0.406358  0.360624\n6   0.567990 -0.256381  0.572804\n7   0.289179  0.324772  0.309701\n8   0.353620  0.241495  0.368311\n9   0.534402  0.000000  0.534402\n10  0.601536 -0.210127  0.633106\n11  0.349288  0.132342  0.390686\n12  0.235447  0.460972  0.283232\n13  0.586957 -0.341253  0.586957\n14  0.529931 -0.075042  0.611384\n15  0.385379  0.126706  0.425090\n16  0.554140 -0.111866  0.605096\n17  0.440427 -0.072395  0.440427\n18  0.407477 -0.013953  0.408411\n19  0.494530 -0.058011  0.494530\n20  0.447307 -0.022617  0.466823\n21  0.708242 -0.233637  0.810357\n22  0.354108  0.196156  0.389518\n23  0.472772  0.042366  0.546205\n24  0.425211 -0.030053  0.437877\n25  0.334118  0.246188  0.335686\n26  0.349462  0.227835  0.386608\n27  0.473438 -0.004403  0.473438\n28  0.426248  0.075275  0.433272",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pk</th>\n      <th>K-k</th>\n      <th>Windiff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.554391</td>\n      <td>-0.202583</td>\n      <td>0.586282</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.380090</td>\n      <td>-0.161110</td>\n      <td>0.380090</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.321965</td>\n      <td>0.328838</td>\n      <td>0.360164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.581089</td>\n      <td>-0.177916</td>\n      <td>0.623496</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.466907</td>\n      <td>0.019918</td>\n      <td>0.544525</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.234568</td>\n      <td>0.406358</td>\n      <td>0.360624</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.567990</td>\n      <td>-0.256381</td>\n      <td>0.572804</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.289179</td>\n      <td>0.324772</td>\n      <td>0.309701</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.353620</td>\n      <td>0.241495</td>\n      <td>0.368311</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.534402</td>\n      <td>0.000000</td>\n      <td>0.534402</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.601536</td>\n      <td>-0.210127</td>\n      <td>0.633106</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.349288</td>\n      <td>0.132342</td>\n      <td>0.390686</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.235447</td>\n      <td>0.460972</td>\n      <td>0.283232</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.586957</td>\n      <td>-0.341253</td>\n      <td>0.586957</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.529931</td>\n      <td>-0.075042</td>\n      <td>0.611384</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.385379</td>\n      <td>0.126706</td>\n      <td>0.425090</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.554140</td>\n      <td>-0.111866</td>\n      <td>0.605096</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.440427</td>\n      <td>-0.072395</td>\n      <td>0.440427</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.407477</td>\n      <td>-0.013953</td>\n      <td>0.408411</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.494530</td>\n      <td>-0.058011</td>\n      <td>0.494530</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.447307</td>\n      <td>-0.022617</td>\n      <td>0.466823</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.708242</td>\n      <td>-0.233637</td>\n      <td>0.810357</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.354108</td>\n      <td>0.196156</td>\n      <td>0.389518</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.472772</td>\n      <td>0.042366</td>\n      <td>0.546205</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.425211</td>\n      <td>-0.030053</td>\n      <td>0.437877</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.334118</td>\n      <td>0.246188</td>\n      <td>0.335686</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.349462</td>\n      <td>0.227835</td>\n      <td>0.386608</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.473438</td>\n      <td>-0.004403</td>\n      <td>0.473438</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.426248</td>\n      <td>0.075275</td>\n      <td>0.433272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = test_set_evaluate_multiple_lstm(model, features, shifts)\n",
    "#temp_y = model.predict(X_train)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model: (1, 16)\n",
      "Finished model: (1, 16)\n",
      "Starting model: (1, 47)\n",
      "Finished model: (1, 47)\n",
      "Starting model: (1, 78)\n",
      "Finished model: (1, 78)\n",
      "Starting model: (1, 109)\n",
      "Finished model: (1, 109)\n",
      "Starting model: (1, 140)\n",
      "Finished model: (1, 140)\n",
      "Starting model: (1, 171)\n",
      "Finished model: (1, 171)\n",
      "Starting model: (1, 202)\n",
      "Finished model: (1, 202)\n",
      "Starting model: (1, 233)\n",
      "Finished model: (1, 233)\n",
      "Starting model: (1, 264)\n",
      "Finished model: (1, 264)\n",
      "Starting model: (1, 295)\n",
      "Finished model: (1, 295)\n",
      "Starting model: (1, 326)\n",
      "Finished model: (1, 326)\n",
      "Starting model: (1, 357)\n",
      "Finished model: (1, 357)\n",
      "Starting model: (1, 388)\n",
      "Finished model: (1, 388)\n",
      "Starting model: (1, 419)\n",
      "Finished model: (1, 419)\n",
      "Starting model: (1, 450)\n",
      "Finished model: (1, 450)\n",
      "Starting model: (1, 481)\n",
      "Finished model: (1, 481)\n",
      "Starting model: (1, 512)\n",
      "Finished model: (1, 512)\n",
      "Starting model: (2, 16)\n",
      "Finished model: (2, 16)\n",
      "Starting model: (2, 47)\n",
      "Finished model: (2, 47)\n",
      "Starting model: (2, 78)\n",
      "Finished model: (2, 78)\n",
      "Starting model: (2, 109)\n",
      "Finished model: (2, 109)\n",
      "Starting model: (2, 140)\n",
      "Finished model: (2, 140)\n",
      "Starting model: (2, 171)\n",
      "Finished model: (2, 171)\n",
      "Starting model: (2, 202)\n",
      "Finished model: (2, 202)\n",
      "Starting model: (2, 233)\n",
      "Finished model: (2, 233)\n",
      "Starting model: (2, 264)\n",
      "Finished model: (2, 264)\n",
      "Starting model: (2, 295)\n",
      "Finished model: (2, 295)\n",
      "Starting model: (2, 326)\n",
      "Finished model: (2, 326)\n",
      "Starting model: (2, 357)\n",
      "Finished model: (2, 357)\n",
      "Starting model: (2, 388)\n",
      "Finished model: (2, 388)\n",
      "Starting model: (2, 419)\n",
      "Finished model: (2, 419)\n",
      "Starting model: (2, 450)\n",
      "Finished model: (2, 450)\n",
      "Starting model: (2, 481)\n",
      "Finished model: (2, 481)\n",
      "Starting model: (2, 512)\n",
      "Finished model: (2, 512)\n",
      "Starting model: (3, 16)\n",
      "Finished model: (3, 16)\n",
      "Starting model: (3, 47)\n",
      "Finished model: (3, 47)\n",
      "Starting model: (3, 78)\n",
      "Finished model: (3, 78)\n",
      "Starting model: (3, 109)\n",
      "Finished model: (3, 109)\n",
      "Starting model: (3, 140)\n",
      "Finished model: (3, 140)\n",
      "Starting model: (3, 171)\n",
      "Finished model: (3, 171)\n",
      "Starting model: (3, 202)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-64-bf9017d9f271>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[1;31m# train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         history=model.fit(X_train, Y_train,\n\u001B[0m\u001B[0;32m     18\u001B[0m                           \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m                           \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1562\u001B[0m                         ):\n\u001B[0;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1564\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1565\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2494\u001B[0m       (graph_function,\n\u001B[0;32m   2495\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2497\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2498\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1860\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1861\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1862\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1863\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1864\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for num_layers in range(1, 5):\n",
    "    # It's 31 per step, because it allows for there to be 16 trials, and for me to not go crazy\n",
    "    for hidden_units in range(16, 513, 31):\n",
    "        #print(\"Starting model: \" + str((num_layers, hidden_units)))\n",
    "        model = Sequential()\n",
    "        # For the input number of units, I'll assume that number of timesteps * features is a good enough value\n",
    "        for _ in range(num_layers):\n",
    "            model.add(Bidirectional(LSTM(hidden_units, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "        model.add(Bidirectional(LSTM(hidden_units, activation='sigmoid', return_sequences=True, dropout=0.3)))\n",
    "        # This last time distributed is super important, it follows the output structure of the paper I've been following closely\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
    "                      metrics=[keras.metrics.Precision(), tf.keras.metrics.Recall()], weighted_metrics=[])\n",
    "\n",
    "        # train the model\n",
    "        history=model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=3,\n",
    "                  #class_weight= {0:1, 1:10},\n",
    "                  # sample_weight_mode='temporal',\n",
    "                  sample_weight=sample_weight,\n",
    "                  validation_split=0.1,\n",
    "                  verbose=1\n",
    "                  )\n",
    "\n",
    "        print(\"Finished model: \" + str((num_layers, hidden_units)) + \" with results: \" + str(history.history['val_acc'][-1]))\n",
    "\n",
    "        hist_results_dict[(num_layers, hidden_units)] = history\n",
    "        # It's -1, to take the last accuracy measure obtained\n",
    "        acc_results_dict[(num_layers, hidden_units)] = history.history['val_acc'][-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "{(1, 16): 0.9919072985649109,\n (1, 47): 0.9919072985649109,\n (1, 78): 0.9919072985649109,\n (1, 109): 0.9919072985649109,\n (1, 140): 0.9919072985649109,\n (1, 171): 0.9919072985649109,\n (1, 202): 0.9919072985649109,\n (1, 233): 0.9919072985649109,\n (1, 264): 0.9919072985649109,\n (1, 295): 0.9919072985649109,\n (1, 326): 0.9919072985649109,\n (1, 357): 0.9919072985649109,\n (1, 388): 0.9919072985649109,\n (1, 419): 0.9919072985649109,\n (1, 450): 0.9919072985649109,\n (1, 481): 0.9919072985649109,\n (1, 512): 0.9919072985649109,\n (2, 16): 0.9919072985649109,\n (2, 47): 0.9919072985649109,\n (2, 78): 0.9919072985649109,\n (2, 109): 0.9919072985649109,\n (2, 140): 0.9919072985649109,\n (2, 171): 0.9919072985649109,\n (2, 202): 0.9919072985649109,\n (2, 233): 0.9919072985649109,\n (2, 264): 0.9919072985649109,\n (2, 295): 0.9919072985649109,\n (2, 326): 0.9919072985649109,\n (2, 357): 0.9919072985649109,\n (2, 388): 0.9919072985649109,\n (2, 419): 0.9919072985649109,\n (2, 450): 0.9919072985649109,\n (2, 481): 0.9919072985649109,\n (2, 512): 0.9919072985649109,\n (3, 16): 0.9919072985649109,\n (3, 47): 0.9919072985649109,\n (3, 78): 0.9919072985649109,\n (3, 109): 0.9919072985649109,\n (3, 140): 0.9919072985649109,\n (3, 171): 0.9919072985649109}"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 2s 4ms/step\n",
      "71/71 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 4ms/step\n",
      "58/58 [==============================] - 0s 4ms/step\n",
      "55/55 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "34/34 [==============================] - 0s 3ms/step\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "44/44 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 3ms/step\n",
      "58/58 [==============================] - 0s 3ms/step\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "55/55 [==============================] - 0s 3ms/step\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "66/66 [==============================] - 0s 3ms/step\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "          Pk  K-k   Windiff\n0   0.372652  0.0  0.372652\n1   0.095525  0.0  0.095525\n2   0.470668  0.0  0.470668\n3   0.477364  0.0  0.477364\n4   0.439832  0.0  0.439832\n5   0.283951  0.0  0.283951\n6   0.397112  0.0  0.397112\n7   0.380597  0.0  0.380597\n8   0.441763  0.0  0.441763\n9   0.534402  0.0  0.534402\n10  0.434300  0.0  0.434300\n11  0.390686  0.0  0.390686\n12  0.364031  0.0  0.364031\n13  0.391304  0.0  0.391304\n14  0.411187  0.0  0.411187\n15  0.424188  0.0  0.424188\n16  0.509554  0.0  0.509554\n17  0.336072  0.0  0.336072\n18  0.336449  0.0  0.336449\n19  0.457330  0.0  0.457330\n20  0.397346  0.0  0.397346\n21  0.375638  0.0  0.375638\n22  0.403683  0.0  0.403683\n23  0.449670  0.0  0.449670\n24  0.372738  0.0  0.372738\n25  0.429804  0.0  0.429804\n26  0.431085  0.0  0.431085\n27  0.470038  0.0  0.470038\n28  0.453604  0.0  0.453604",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pk</th>\n      <th>K-k</th>\n      <th>Windiff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.372652</td>\n      <td>0.0</td>\n      <td>0.372652</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.095525</td>\n      <td>0.0</td>\n      <td>0.095525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.470668</td>\n      <td>0.0</td>\n      <td>0.470668</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.477364</td>\n      <td>0.0</td>\n      <td>0.477364</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.439832</td>\n      <td>0.0</td>\n      <td>0.439832</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.283951</td>\n      <td>0.0</td>\n      <td>0.283951</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.397112</td>\n      <td>0.0</td>\n      <td>0.397112</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.380597</td>\n      <td>0.0</td>\n      <td>0.380597</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.441763</td>\n      <td>0.0</td>\n      <td>0.441763</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.534402</td>\n      <td>0.0</td>\n      <td>0.534402</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.434300</td>\n      <td>0.0</td>\n      <td>0.434300</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.390686</td>\n      <td>0.0</td>\n      <td>0.390686</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.364031</td>\n      <td>0.0</td>\n      <td>0.364031</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.391304</td>\n      <td>0.0</td>\n      <td>0.391304</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.411187</td>\n      <td>0.0</td>\n      <td>0.411187</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.424188</td>\n      <td>0.0</td>\n      <td>0.424188</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.509554</td>\n      <td>0.0</td>\n      <td>0.509554</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.336072</td>\n      <td>0.0</td>\n      <td>0.336072</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.336449</td>\n      <td>0.0</td>\n      <td>0.336449</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.457330</td>\n      <td>0.0</td>\n      <td>0.457330</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.397346</td>\n      <td>0.0</td>\n      <td>0.397346</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.375638</td>\n      <td>0.0</td>\n      <td>0.375638</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.403683</td>\n      <td>0.0</td>\n      <td>0.403683</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.449670</td>\n      <td>0.0</td>\n      <td>0.449670</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.372738</td>\n      <td>0.0</td>\n      <td>0.372738</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.429804</td>\n      <td>0.0</td>\n      <td>0.429804</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.431085</td>\n      <td>0.0</td>\n      <td>0.431085</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.470038</td>\n      <td>0.0</td>\n      <td>0.470038</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.453604</td>\n      <td>0.0</td>\n      <td>0.453604</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = test_set_evaluate_multiple_lstm(model, features, shifts)\n",
    "#temp_y = model.predict(X_train)\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Pk         0.404572\nK-k        0.000000\nWindiff    0.404572\ndtype: float64"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483/1483 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[0.00627282],\n        [0.01584293],\n        [0.01336911],\n        [0.02408313],\n        [0.01425999]],\n\n       [[0.00942823],\n        [0.00914664],\n        [0.01536419],\n        [0.0124401 ],\n        [0.00516671]],\n\n       [[0.00379193],\n        [0.00422932],\n        [0.00482995],\n        [0.00295994],\n        [0.00844802]],\n\n       ...,\n\n       [[0.01065987],\n        [0.02366466],\n        [0.00473628],\n        [0.0050675 ],\n        [0.00676939]],\n\n       [[0.02293292],\n        [0.00628696],\n        [0.00566995],\n        [0.00733351],\n        [0.00526068]],\n\n       [[0.00610961],\n        [0.00701646],\n        [0.0087015 ],\n        [0.00562242],\n        [0.00662829]]], dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_y = model.predict(X_train)\n",
    "temp_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's working which is good. It is giving garbage results though."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
