{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0/\"\n",
    "\n",
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,0.3)\n",
    "\n",
    "X = pd.concat([X_train,X_test])\n",
    "y = pd.concat([y_train,y_test])\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "X_train = X_train[features_selected]\n",
    "X_test = X_test[features_selected]\n",
    "\n",
    "# def count_duplicate(df1,df2,feature):\n",
    "#     duplicate_count = 0\n",
    "#     for index, row in df2.iterrows():\n",
    "#         if df1.iloc[index][feature]==df2.iloc[index][feature]:\n",
    "#             duplicate_count+=1\n",
    "#     return duplicate_count\n",
    "\n",
    "# for feature in features_selected:\n",
    "#     print(count_duplicate(X_train,X_test,feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    int_y_pred = (np.array(y_pred))\n",
    "    int_y_true = (np.array(y_true))\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(int_y_true,int_y_pred,k))\n",
    "    print('- pk:',sm.get_pk(int_y_true,int_y_pred,k))\n",
    "    print('- kkappa:',sm.get_k_kappa(int_y_true,int_y_pred,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train,tuning, best_criterion=None,best_max_depth=None,best_min_sample_leaf=None):\n",
    "    if tuning:\n",
    "        clf = DecisionTreeClassifier(criterion=best_criterion,max_depth=best_max_depth,min_samples_leaf=best_min_sample_leaf)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree_hyperparam(X,y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    std_slc = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                        ('dec_tree', clf)])\n",
    "\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy','log_loss']\n",
    "    max_depth = [2,5,10,15,20,30,50,100]\n",
    "    min_samples_leaf=[5,10,20,50,100]\n",
    "\n",
    "    parameters = dict(dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth,\n",
    "                      dec_tree__min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "\n",
    "    best_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    best_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "    best_min_samples_leaf = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf']\n",
    "\n",
    "    print('Best criterion:', best_criterion)\n",
    "    print('Best max_depth:', best_max_depth)\n",
    "    print('Best min_sample_leaf:', best_min_samples_leaf)\n",
    "\n",
    "    return best_criterion,best_max_depth,best_min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best criterion: gini\n",
      "Best max_depth: 2\n",
      "Best min_sample_leaf: 10\n"
     ]
    }
   ],
   "source": [
    "best_criterion,best_max_depth,best_min_sample_leaf = DecTree_hyperparam(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal DST\n",
      "147.0\n",
      "k = 61\n",
      "- windiff: 0.5313353358820316\n",
      "- pk: 0.448798470780994\n",
      "- kkappa: 0.07130356481851277\n",
      "-------------Tuned DST\n",
      "0.0\n",
      "k = 61\n",
      "- windiff: 0.3718596395412343\n",
      "- pk: 0.3718596395412343\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,False)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,True,best_criterion,best_max_depth,best_min_sample_leaf)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from model_trainer_and_tester import read_in_dataset, test_set_evaluate_multiple\n",
    "\n",
    "# Pick the features that you want, and vary them as needed\n",
    "features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "# Represents the context that is being used for training and for evaluation\n",
    "shifts = [-2, -1, 1, 2]\n",
    "\n",
    "X_train, y_train = read_in_dataset(features, shifts, to_read='train')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "results = test_set_evaluate_multiple(clf, features, shifts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Pk         0.570373\nK-k       -0.066525\nWindiff    0.570373\ndtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
