{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Test basic classification models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import model_trainer_and_tester as mtt\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "importlib.reload(sm)\n",
    "importlib.reload(mtt)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de08adfa",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77f44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002 Bns003 Bro003 Bro004 Bro005 Bro007 Bro008 Bro010 Bro011 Bro012 Bro013 Bro014 Bro015 Bro016 Bro017 Bro018 Bro019 Bro021 Bro022 Bro023 Bro024 Bro025 Bro026 Bro027 Bro028 Bsr001 Btr001 Btr002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_f0_stds_fixed/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split=0.3\n",
    "\n",
    "# Represents the context that is being used for training and for evaluation\n",
    "shifts = [-3,-2,-1, 1,2,3]\n",
    "\n",
    "subtopic_lvl = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29ab19a7",
   "metadata": {},
   "source": [
    "### Basic random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "894a222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6781fdf",
   "metadata": {},
   "source": [
    "### Basic random split + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29a92679",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../topic_boundaries/Bro016_topic_boundaries_lvl_3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(features_selected,shifts,split,subtopic_lvl)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:317\u001b[0m, in \u001b[0;36mread_in_dataset_all_together\u001b[1;34m(features, shifts, test_split, subtopic_lvl)\u001b[0m\n\u001b[0;32m    314\u001b[0m test_selected_meetings \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(dataset_list) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(train_selected_meetings))\n\u001b[0;32m    316\u001b[0m base_df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../results_merged_f0_stds_fixed/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m train_selected_meetings[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 317\u001b[0m segment_boundaries_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../topic_boundaries/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m train_selected_meetings[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_topic_boundaries_lvl_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(subtopic_lvl)\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    319\u001b[0m base_y_train \u001b[39m=\u001b[39m []\n\u001b[0;32m    320\u001b[0m \u001b[39mfor\u001b[39;00m segId \u001b[39min\u001b[39;00m base_df_train[\u001b[39m'\u001b[39m\u001b[39msegID\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../topic_boundaries/Bro016_topic_boundaries_lvl_3.csv'"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(features_selected,shifts,split,subtopic_lvl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe08e24",
   "metadata": {},
   "source": [
    "### Constant split + context (to compare with biLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "579f4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const, y_train_const = mtt.read_in_dataset(features_selected, shifts, to_read='train')\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_const, y_train_const)\n",
    "\n",
    "results_const = mtt.test_set_evaluate_multiple(clf, features_selected, shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dd60c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pk         0.572100\n",
       "K-k       -0.066113\n",
       "Windiff    0.572100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_const.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on commonly used models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb95e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(np.array(y_true),np.array(y_pred),k))\n",
    "    print('- pk:',sm.get_pk(np.array(y_true),np.array(y_pred),k))\n",
    "    print('- kkappa:',sm.get_k_kappa(np.array(y_true),np.array(y_pred),k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cbc4096",
   "metadata": {},
   "source": [
    "### Decision Tree classifier with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf9d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train,tuning=False, best_criterion=None,best_max_depth=None,best_min_sample_leaf=None):\n",
    "    if tuning:\n",
    "        clf = DecisionTreeClassifier(criterion=best_criterion,max_depth=best_max_depth,min_samples_leaf=best_min_sample_leaf)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af133e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree_hyperparam(X,y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    std_slc = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),('dec_tree', clf)])\n",
    "\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy','log_loss']\n",
    "    max_depth = [2,5,10,15,20,30,50,100]\n",
    "    min_samples_leaf=[5,10,20,50,100]\n",
    "\n",
    "    parameters = dict(dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth,\n",
    "                      dec_tree__min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "\n",
    "    best_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    best_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "    best_min_samples_leaf = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf']\n",
    "\n",
    "    print('Best criterion:', best_criterion)\n",
    "    print('Best max_depth:', best_max_depth)\n",
    "    print('Best min_sample_leaf:', best_min_samples_leaf)\n",
    "\n",
    "    return best_criterion,best_max_depth,best_min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e92bf84a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecTree_hyperparam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_criterion,best_max_depth,best_min_sample_leaf \u001b[39m=\u001b[39m DecTree_hyperparam(X_train,y_train)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Tuned DST\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m DT_y_predicted \u001b[39m=\u001b[39m DecTree(X_train,X_test,y_train,\u001b[39mTrue\u001b[39;00m,best_criterion,best_max_depth,best_min_sample_leaf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecTree_hyperparam' is not defined"
     ]
    }
   ],
   "source": [
    "best_criterion,best_max_depth,best_min_sample_leaf = DecTree_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,True,best_criterion,best_max_depth,best_min_sample_leaf)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d2c5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal DST\n",
      "417 312\n",
      "k = 44\n",
      "- windiff: 0.5588575560375995\n",
      "- pk: 0.47736804049168474\n",
      "- kkappa: 0.03370331277192754\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,False)\n",
    "print(sum(DT_y_predicted),sum(y_test))\n",
    "print_eval(DT_y_predicted,y_test)\n",
    "indexes = [index for index in range(len(DT_y_predicted)) if (DT_y_predicted[index]==1)and(y_test[index]==1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,X_test,y_train,tuning=False,best_gamma=None,best_C=None):\n",
    "    if tuning:\n",
    "        clf = SVC(gamma=best_gamma,C=best_C) \n",
    "    else:\n",
    "        clf = SVC() \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_hyperparam(X,y):\n",
    "    param_grid = {\n",
    "        \"gamma\": [0.1, 1.0, 10],\n",
    "        \"C\": [0.1, 1.0, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_gamma = grid_search.best_estimator_.get_params()['gamma']\n",
    "    best_C = grid_search.best_estimator_.get_params()['C']\n",
    "    print('Best gamma:', best_gamma)\n",
    "    print('Best C:', best_C)\n",
    "\n",
    "    return best_gamma,best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ad769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best gamma: 0.1\n",
      "Best C: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_gamma,best_C = SVM_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,True,best_gamma,best_C)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal SVM\n",
      "0.0 288.0\n",
      "k = 46\n",
      "- windiff: 0.4033554051037869\n",
      "- pk: 0.4033554051037869\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,False)\n",
    "print(sum(SVM_y_predicted),sum(y_test))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405deb78",
   "metadata": {},
   "source": [
    "### Naive Bayes for binary class with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e84d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train,X_test,y_train,tuning=False,best_var_smoothing=None):\n",
    "\n",
    "    if tuning:\n",
    "        clf = GaussianNB(var_smoothing=best_var_smoothing) \n",
    "    else:\n",
    "        clf = GaussianNB() \n",
    "\n",
    "    clf.fit(X_train, np.ravel(y_train)) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_hyperparam(X,y):\n",
    "        param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "        nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "        nbModel_grid.fit(X, y)\n",
    "\n",
    "        best_var_smoothing = nbModel_grid.best_estimator_.get_params()['var_smoothing']\n",
    "        print('Best var_smoothing:', best_var_smoothing)\n",
    "\n",
    "        return best_var_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc781deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naiveBayes_hyperparam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_var_smoothing \u001b[39m=\u001b[39m naiveBayes_hyperparam(X_train,y_train)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Tuned NB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m NB_y_predicted \u001b[39m=\u001b[39m naiveBayes(X_train,X_test,y_train,\u001b[39mTrue\u001b[39;00m,best_var_smoothing)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'naiveBayes_hyperparam' is not defined"
     ]
    }
   ],
   "source": [
    "best_var_smoothing = naiveBayes_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,True,best_var_smoothing)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b72eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal NB\n",
      "216 98\n",
      "k = 121\n",
      "- windiff: 0.5901898734177216\n",
      "- pk: 0.4794720186542305\n",
      "- kkappa: 0.010325750790288572\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,False)\n",
    "print(sum(NB_y_predicted),sum(y_test))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c46a4f6",
   "metadata": {},
   "source": [
    "## Multiple runs of each algo with different random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ce49c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "\n",
    "    windiff = sm.get_windiff(np.array(y_true),np.array(y_pred),k)\n",
    "    pk = sm.get_pk(np.array(y_true),np.array(y_pred),k)\n",
    "    kappa = sm.get_k_kappa(np.array(y_true),np.array(y_pred),k)\n",
    "\n",
    "    return windiff,pk,kappa\n",
    "\n",
    "def get_avg_eval(eval):\n",
    "    windiffs = [row[0] for row in eval]\n",
    "    pks = [row[1] for row in eval]\n",
    "    kappas = [row[2] for row in eval]\n",
    "\n",
    "    print('-> windiff:',windiffs)\n",
    "    print('-> pk:',pks)\n",
    "    print('-> k-kappa:',kappas)\n",
    "    print()\n",
    "    print('-> windiff - mean:',statistics.mean(windiffs),', - var:',statistics.variance(windiffs))\n",
    "    print('-> pk - mean:',statistics.mean(pks),', - var:',statistics.variance(pks))\n",
    "    print('-> k-kappa - mean:',statistics.mean(kappas),', - var:',statistics.variance(kappas))\n",
    "\n",
    "\n",
    "def run_model(iterations,features,shift,split,subtopic_lvl):\n",
    "    DT_scores = []\n",
    "    # SVM_scores = []\n",
    "    NB_scores = []\n",
    "    for k in range(iterations):\n",
    "        X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(features,shifts,split,subtopic_lvl)\n",
    "        \n",
    "        DT_scores.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "        # SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\n",
    "        NB_scores.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "    \n",
    "    return DT_scores,NB_scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e9e6c8",
   "metadata": {},
   "source": [
    "### Test different context levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0f4df40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON CONTEXT LEVEL WITH SPLIT: 0.3 (of testing), ITERATIONS: 1 , SUBTOPIC LVL: 2 , AND FEATURES: ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [60], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i,\u001b[39mlen\u001b[39m(shifts)\u001b[39m-\u001b[39mi):\n\u001b[0;32m     15\u001b[0m     curr_shifts\u001b[39m.\u001b[39mappend(shifts[j])\n\u001b[1;32m---> 17\u001b[0m DT_scores, NB_scores \u001b[39m=\u001b[39m run_model(iterations,features_selected,curr_shifts,split,subtopic_lvl)\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-> Context level =\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mlen\u001b[39m(curr_shifts)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m----- DT:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [59], line 31\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(iterations, features, shift, split, subtopic_lvl)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[0;32m     29\u001b[0m     X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(features,shifts,split,subtopic_lvl)\n\u001b[1;32m---> 31\u001b[0m     DT_scores\u001b[39m.\u001b[39mappend(get_eval(DecTree(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;49;00m),y_test))\n\u001b[0;32m     32\u001b[0m     \u001b[39m# SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     NB_scores\u001b[39m.\u001b[39mappend(get_eval(naiveBayes(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;00m),y_test))\n",
      "Cell \u001b[1;32mIn [8], line 6\u001b[0m, in \u001b[0;36mDecTree\u001b[1;34m(X_train, X_test, y_train, tuning, best_criterion, best_max_depth, best_min_sample_leaf)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     clf \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m----> 6\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m y_predicted \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m y_predicted\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "subtopic_lvl = 2\n",
    "\n",
    "shifts = [-10,-9,-8,-7,-6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6,7,8,9,10]\n",
    "\n",
    "iterations = 1\n",
    "print('EXPERIMENTING ON CONTEXT LEVEL WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SUBTOPIC LVL:',subtopic_lvl,', AND FEATURES:',features_selected,)\n",
    "i=0\n",
    "while i<len(shifts)/2:\n",
    "    # get current shift\n",
    "    curr_shifts=[]\n",
    "    for j in range(i,len(shifts)-i):\n",
    "        curr_shifts.append(shifts[j])\n",
    "    \n",
    "    DT_scores, NB_scores = run_model(iterations,features_selected,curr_shifts,split,subtopic_lvl)\n",
    "    \n",
    "    print('-> Context level =',len(curr_shifts)/2)\n",
    "    print('----- DT:')\n",
    "    get_avg_eval(DT_scores)\n",
    "    print()\n",
    "    # print('----- SVM:')\n",
    "    # get_avg_eval(SVM_scores)\n",
    "    print()\n",
    "    print('----- NB:')\n",
    "    get_avg_eval(NB_scores)\n",
    "    print()\n",
    "    print()\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9032ba3a",
   "metadata": {},
   "source": [
    "### Test different subtopic levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8924d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON SUBTOPIC LEVEL WITH SPLIT: 0.3 (of testing), ITERATIONS: 5 , SHIFTS: [-2, -1, 1, 2] , AND FEATURES: ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [61], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(subtopic_lvls)):\n\u001b[0;32m     12\u001b[0m     curr_subtopic_lvl \u001b[39m=\u001b[39m subtopic_lvls[i]\n\u001b[1;32m---> 14\u001b[0m     DT_scores, NB_scores \u001b[39m=\u001b[39m run_model(iterations,features_selected,shifts,split,curr_subtopic_lvl)\n\u001b[0;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-> Subtopic level =\u001b[39m\u001b[39m'\u001b[39m,curr_subtopic_lvl)\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m----- DT:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [59], line 31\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(iterations, features, shift, split, subtopic_lvl)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[0;32m     29\u001b[0m     X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(features,shifts,split,subtopic_lvl)\n\u001b[1;32m---> 31\u001b[0m     DT_scores\u001b[39m.\u001b[39mappend(get_eval(DecTree(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;49;00m),y_test))\n\u001b[0;32m     32\u001b[0m     \u001b[39m# SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     NB_scores\u001b[39m.\u001b[39mappend(get_eval(naiveBayes(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;00m),y_test))\n",
      "Cell \u001b[1;32mIn [59], line 4\u001b[0m, in \u001b[0;36mget_eval\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_eval\u001b[39m(y_pred,y_true):\n\u001b[0;32m      2\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m,np\u001b[39m.\u001b[39mfloor((\u001b[39mlen\u001b[39m(y_true)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m(\u001b[39msum\u001b[39m(y_true)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)))))\n\u001b[1;32m----> 4\u001b[0m     windiff \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mget_windiff(np\u001b[39m.\u001b[39;49marray(y_true),np\u001b[39m.\u001b[39;49marray(y_pred),k)\n\u001b[0;32m      5\u001b[0m     pk \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mget_pk(np\u001b[39m.\u001b[39marray(y_true),np\u001b[39m.\u001b[39marray(y_pred),k)\n\u001b[0;32m      6\u001b[0m     kappa \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mget_k_kappa(np\u001b[39m.\u001b[39marray(y_true),np\u001b[39m.\u001b[39marray(y_pred),k)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model\\scoring_metrics.py:22\u001b[0m, in \u001b[0;36mget_windiff\u001b[1;34m(ref, pred, k)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[39m# Need to estimate it manually in case it is None. Because some other pieces of code use this\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(\u001b[39mlen\u001b[39m(ref) \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mcount_nonzero(ref) \u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)))\n\u001b[1;32m---> 22\u001b[0m \u001b[39mreturn\u001b[39;00m windowdiff(ref\u001b[39m.\u001b[39;49mtolist(), pred\u001b[39m.\u001b[39;49mtolist(), k, boundary\u001b[39m=\u001b[39;49m\u001b[39m1.\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\metrics\\segmentation.py:87\u001b[0m, in \u001b[0;36mwindowdiff\u001b[1;34m(seg1, seg2, k, boundary, weighted)\u001b[0m\n\u001b[0;32m     85\u001b[0m wd \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(seg1) \u001b[39m-\u001b[39m k \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m---> 87\u001b[0m     ndiff \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39;49m(seg1[i : i \u001b[39m+\u001b[39;49m k]\u001b[39m.\u001b[39;49mcount(boundary) \u001b[39m-\u001b[39;49m seg2[i : i \u001b[39m+\u001b[39;49m k]\u001b[39m.\u001b[39;49mcount(boundary))\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m weighted:\n\u001b[0;32m     89\u001b[0m         wd \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m ndiff\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "shifts = [-2, -1, 1, 2]\n",
    "\n",
    "subtopic_lvls = [0,1,2]\n",
    "\n",
    "iterations = 5\n",
    "print('EXPERIMENTING ON SUBTOPIC LEVEL WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SHIFTS:',shifts,', AND FEATURES:',features_selected,)\n",
    "\n",
    "for i in range(len(subtopic_lvls)):\n",
    "    curr_subtopic_lvl = subtopic_lvls[i]\n",
    "\n",
    "    DT_scores, NB_scores = run_model(iterations,features_selected,shifts,split,curr_subtopic_lvl)\n",
    "    \n",
    "    print('-> Subtopic level =',curr_subtopic_lvl)\n",
    "    print('----- DT:')\n",
    "    get_avg_eval(DT_scores)\n",
    "    print()\n",
    "    # print('----- SVM:')\n",
    "    # get_avg_eval(SVM_scores)\n",
    "    print()\n",
    "    print('----- NB:')\n",
    "    get_avg_eval(NB_scores)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59b09e6",
   "metadata": {},
   "source": [
    "### Test different combinations of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5b8ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON FEATURES COMBINATIONS WITH SPLIT: 0.3 (of testing), ITERATIONS: 2 , SHIFTS: [-2, -1, 1, 2] , AND SUBTOPIC LVL: 1\n",
      "------ALL COMBINATIONS OF LENGTH 1 ------\n",
      "-> Features = ['pause']\n",
      "----- DT:\n",
      "-> windiff: [0.5622854340362923, 0.5340374763141273]\n",
      "-> pk: [0.47218524486793245, 0.464804547687557]\n",
      "-> k-kappa: [0.0594864010078124, 0.03817162002451795]\n",
      "\n",
      "-> windiff - mean: 0.5481614551752099 , - var: 0.00039897355773660864\n",
      "-> pk - mean: 0.46849489627774477 , - var: 2.72373454342009e-05\n",
      "-> k-kappa - mean: 0.04882901051616517 , - var: 0.0002271599441829054\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5265536327331325, 0.45368096006737313]\n",
      "-> pk: [0.4567715266587263, 0.400835146326058]\n",
      "-> k-kappa: [0.0043759265917455775, 0.07519984148327805]\n",
      "\n",
      "-> windiff - mean: 0.4901172964002528 , - var: 0.0026552132107254558\n",
      "-> pk - mean: 0.4288033364923921 , - var: 0.0015644393223604599\n",
      "-> k-kappa - mean: 0.03978788403751181 , - var: 0.0025080134602815172\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange']\n",
      "----- DT:\n",
      "-> windiff: [0.39705882352941174, 0.4136229990199281]\n",
      "-> pk: [0.39705882352941174, 0.4136229990199281]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> pk - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.39705882352941174, 0.4136229990199281]\n",
      "-> pk: [0.39705882352941174, 0.4136229990199281]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> pk - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5324642662530913, 0.5465580678637693]\n",
      "-> pk: [0.4672004023976192, 0.45457404320890593]\n",
      "-> k-kappa: [0.029505189336403087, 0.08246516729177422]\n",
      "\n",
      "-> windiff - mean: 0.5395111670584303 , - var: 9.931762192057446e-05\n",
      "-> pk - mean: 0.46088722280326255 , - var: 7.971247318120167e-05\n",
      "-> k-kappa - mean: 0.055985178314088654 , - var: 0.0014023796325166983\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4113258163222534, 0.3981571747539231]\n",
      "-> pk: [0.4113258163222534, 0.3981571747539231]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.40474149553808825 , - var: 8.670656037757845e-05\n",
      "-> pk - mean: 0.40474149553808825 , - var: 8.670656037757845e-05\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.49897610921501706, 0.4945207317618643]\n",
      "-> pk: [0.4504400934075804, 0.46092946280806907]\n",
      "-> k-kappa: [0.03705410705237311, -0.023748939658868377]\n",
      "\n",
      "-> windiff - mean: 0.4967484204884407 , - var: 9.925194125031057e-06\n",
      "-> pk - mean: 0.4556847781078247 , - var: 5.5013435209954e-05\n",
      "-> k-kappa - mean: 0.006652583696752366 , - var: 0.001848505244684707\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4002514819471888, 0.3988459990159682]\n",
      "-> pk: [0.4002514819471888, 0.3988459990159682]\n",
      "-> k-kappa: [0.0, 0.0032704021644514437]\n",
      "\n",
      "-> windiff - mean: 0.3995487404815785 , - var: 9.876911349762448e-07\n",
      "-> pk - mean: 0.3995487404815785 , - var: 9.876911349762448e-07\n",
      "-> k-kappa - mean: 0.0016352010822257219 , - var: 5.347765158624344e-06\n",
      "\n",
      "\n",
      "-> Features = ['f0_baseline_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5275095275095275, 0.5129823810542835]\n",
      "-> pk: [0.4805194805194805, 0.4536700192595763]\n",
      "-> k-kappa: [-0.018283729100434482, 0.037391591581407944]\n",
      "\n",
      "-> windiff - mean: 0.5202459542819056 , - var: 0.00010551899206605416\n",
      "-> pk - mean: 0.46709474988952837 , - var: 0.000360446784973549\n",
      "-> k-kappa - mean: 0.009553931240486731 , - var: 0.0015498706665129955\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4087024087024087, 0.3917897139596262]\n",
      "-> pk: [0.4087024087024087, 0.38815179399386546]\n",
      "-> k-kappa: [0.0, 0.009079378911669624]\n",
      "\n",
      "-> windiff - mean: 0.4002460613310175 , - var: 0.00014301962173127154\n",
      "-> pk - mean: 0.3984271013481371 , - var: 0.00021116388244949702\n",
      "-> k-kappa - mean: 0.004539689455834812 , - var: 4.1217560710835545e-05\n",
      "\n",
      "\n",
      "\n",
      "------ALL COMBINATIONS OF LENGTH 2 ------\n",
      "-> Features = ['pause', 'speakerChange']\n",
      "----- DT:\n",
      "-> windiff: [0.625154130702836, 0.5780664316199666]\n",
      "-> pk: [0.4953106901318985, 0.4835776581926146]\n",
      "-> k-kappa: [0.047622298665306755, 0.035445417654770175]\n",
      "\n",
      "-> windiff - mean: 0.6016102811614013 , - var: 0.001108625702459428\n",
      "-> pk - mean: 0.48944417416225655 , - var: 6.88320192441278e-05\n",
      "-> k-kappa - mean: 0.04153385816003846 , - var: 7.413821557238317e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4972536711131039, 0.4663945073297458]\n",
      "-> pk: [0.4248402645443336, 0.40642048617554277]\n",
      "-> k-kappa: [0.07239160195342516, 0.07751046598792205]\n",
      "\n",
      "-> windiff - mean: 0.48182408922142483 , - var: 0.0004761439947040608\n",
      "-> pk - mean: 0.4156303753599382 , - var: 0.00016964411757768727\n",
      "-> k-kappa - mean: 0.0749510339706736 , - var: 1.31013845018329e-05\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5255471979399607, 0.5179536447700253]\n",
      "-> pk: [0.4396218743647083, 0.4511828990032425]\n",
      "-> k-kappa: [0.10712551583087733, 0.06616251733938035]\n",
      "\n",
      "-> windiff - mean: 0.521750421354993 , - var: 2.8831024872318627e-05\n",
      "-> pk - mean: 0.44540238668397536 , - var: 6.682864534639742e-05\n",
      "-> k-kappa - mean: 0.08664401658512884 , - var: 0.000838983622707192\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.46029003184929185, 0.47295944918137783]\n",
      "-> pk: [0.411093040590906, 0.41975901685280814]\n",
      "-> k-kappa: [0.04877254824734451, 0.03913617894476837]\n",
      "\n",
      "-> windiff - mean: 0.46662474051533487 , - var: 8.02570677672804e-05\n",
      "-> pk - mean: 0.4154260287218571 , - var: 3.7549572285925614e-05\n",
      "-> k-kappa - mean: 0.04395436359605644 , - var: 4.642980666781592e-05\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5237683014038917, 0.5149293380087132]\n",
      "-> pk: [0.4603861643268471, 0.45570785959692556]\n",
      "-> k-kappa: [0.03873924635552089, 0.033420001641914644]\n",
      "\n",
      "-> windiff - mean: 0.5193488197063025 , - var: 3.906363695065302e-05\n",
      "-> pk - mean: 0.45804701196188635 , - var: 1.0943267573003098e-05\n",
      "-> k-kappa - mean: 0.036079623998717766 , - var: 1.4147182161613988e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.49715834242914675, 0.4923316686147416]\n",
      "-> pk: [0.44088975874139036, 0.4092374172068147]\n",
      "-> k-kappa: [0.007897508924640119, 0.09678968071145001]\n",
      "\n",
      "-> windiff - mean: 0.49474500552194417 , - var: 1.1648390055332218e-05\n",
      "-> pk - mean: 0.42506358797410254 , - var: 0.0005009353623107109\n",
      "-> k-kappa - mean: 0.05234359481804507 , - var: 0.00395090910248786\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'f0_baseline_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5179174867243492, 0.5787574117040475]\n",
      "-> pk: [0.4585762560808051, 0.4806098773616175]\n",
      "-> k-kappa: [0.036977557175158896, 0.04210330314071717]\n",
      "\n",
      "-> windiff - mean: 0.5483374492141984 , - var: 0.001850748235767656\n",
      "-> pk - mean: 0.46959306672121126 , - var: 0.00024274023337313402\n",
      "-> k-kappa - mean: 0.03954043015793803 , - var: 1.3136635851718457e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4670058301459393, 0.4119618458365558]\n",
      "-> pk: [0.416131308255041, 0.3945788678967333]\n",
      "-> k-kappa: [0.06566811229716217, 0.02189962355823541]\n",
      "\n",
      "-> windiff - mean: 0.4394838379912476 , - var: 0.001514920104325829\n",
      "-> pk - mean: 0.40535508807588716 , - var: 0.00023225384269920577\n",
      "-> k-kappa - mean: 0.04378386792769879 , - var: 0.0009578403032447794\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange', 'similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5354962497819641, 0.5125891733109526]\n",
      "-> pk: [0.4655067155067155, 0.4409987410826689]\n",
      "-> k-kappa: [0.04561136730943371, 0.08300125028904579]\n",
      "\n",
      "-> windiff - mean: 0.5240427115464583 , - var: 0.0002623670762243851\n",
      "-> pk - mean: 0.4532527282946922 , - var: 0.0003003204051848616\n",
      "-> k-kappa - mean: 0.06430630879923975 , - var: 0.0006990016746145425\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.40118611547182975, 0.39592950062945864]\n",
      "-> pk: [0.40118611547182975, 0.39592950062945864]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.3985578080506442 , - var: 1.3815999800518125e-05\n",
      "-> pk - mean: 0.3985578080506442 , - var: 1.3815999800518125e-05\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange', 'f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.47677884823087224, 0.5125868215060086]\n",
      "-> pk: [0.4501663282498812, 0.45150858108853037]\n",
      "-> k-kappa: [0.004753208924599602, 0.049661517489607926]\n",
      "\n",
      "-> windiff - mean: 0.49468283486844045 , - var: 0.0006411054750364416\n",
      "-> pk - mean: 0.4508374546692058 , - var: 9.008213414309094e-07\n",
      "-> k-kappa - mean: 0.027207363207103763 , - var: 0.001008378089085\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.41806713612995205, 0.39186358457976556]\n",
      "-> pk: [0.41461096470384934, 0.39186358457976556]\n",
      "-> k-kappa: [0.0014731907136627017, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4049653603548588 , - var: 0.0003433130569216406\n",
      "-> pk - mean: 0.4032372746418075 , - var: 0.00025872165125478096\n",
      "-> k-kappa - mean: 0.0007365953568313509 , - var: 1.0851454394110102e-06\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m NB_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m---> 23\u001b[0m     X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(feature_comb,shifts,split,subtopic_lvl)        \n\u001b[0;32m     25\u001b[0m     \u001b[39m# X_train = X_train[feature_comb]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39m# X_test = X_test[feature_comb]\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     DT_scores\u001b[39m.\u001b[39mappend(get_eval(DecTree(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;00m),y_test))\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:371\u001b[0m, in \u001b[0;36mread_in_dataset_all_together\u001b[1;34m(features, shifts, test_split, subtopic_lvl)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         base_y\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 371\u001b[0m temp_df \u001b[39m=\u001b[39m transform_rows(temp_df, features, shifts)\n\u001b[0;32m    373\u001b[0m base_df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([base_df_test, temp_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    374\u001b[0m base_y_test \u001b[39m=\u001b[39m base_y_test \u001b[39m+\u001b[39m base_y\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:407\u001b[0m, in \u001b[0;36mtransform_rows\u001b[1;34m(dataframe, features, shifts)\u001b[0m\n\u001b[0;32m    404\u001b[0m filtered_df \u001b[39m=\u001b[39m dataframe[features]\n\u001b[0;32m    405\u001b[0m filtered_df \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mboundary\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m temp_df \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39;49madd_suffix(\u001b[39m'\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Doing a filter on nans, just in case\u001b[39;00m\n\u001b[0;32m    409\u001b[0m temp_df \u001b[39m=\u001b[39m handle_nas(temp_df)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4747\u001b[0m, in \u001b[0;36mNDFrame.add_suffix\u001b[1;34m(self, suffix)\u001b[0m\n\u001b[0;32m   4742\u001b[0m mapper \u001b[39m=\u001b[39m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis_name: f}\n\u001b[0;32m   4743\u001b[0m \u001b[39m# error: Incompatible return value type (got \"Optional[NDFrameT]\",\u001b[39;00m\n\u001b[0;32m   4744\u001b[0m \u001b[39m# expected \"NDFrameT\")\u001b[39;00m\n\u001b[0;32m   4745\u001b[0m \u001b[39m# error: Argument 1 to \"rename\" of \"NDFrame\" has incompatible type\u001b[39;00m\n\u001b[0;32m   4746\u001b[0m \u001b[39m# \"**Dict[str, partial[str]]\"; expected \"Union[str, int, None]\"\u001b[39;00m\n\u001b[1;32m-> 4747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rename(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:1076\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   1073\u001b[0m         index \u001b[39m=\u001b[39m mapper\n\u001b[0;32m   1075\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_inplace_and_allows_duplicate_labels(inplace)\n\u001b[1;32m-> 1076\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1078\u001b[0m \u001b[39mfor\u001b[39;00m axis_no, replacements \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m((index, columns)):\n\u001b[0;32m   1079\u001b[0m     \u001b[39mif\u001b[39;00m replacements \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:6373\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6263\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   6264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, deep: bool_t \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   6265\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6266\u001b[0m \u001b[39m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6267\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6371\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[0;32m   6372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6373\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[0;32m   6374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcopy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:645\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m--> 645\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mcopy\u001b[39;49m\u001b[39m\"\u001b[39;49m, deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[0;32m    646\u001b[0m new_refs: \u001b[39mlist\u001b[39m[weakref\u001b[39m.\u001b[39mref \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m deep:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:348\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    347\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    349\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:550\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    548\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 550\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(values, placement\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr_locs, ndim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002 Bns003 Bro003 Bro004 Bro005 Bro007 Bro008 Bro010 Bro011 Bro012 Bro013 Bro014 Bro015 Bro016 Bro017 Bro018 Bro019 Bro021 Bro022 Bro023 Bro024 Bro025 Bro026 Bro027 Bro028 Bsr001 Btr001 Btr002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_f0_stds_fixed/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "split = 0.3\n",
    "shifts = [-2, -1, 1, 2]\n",
    "subtopic_lvl = 1\n",
    "\n",
    "iterations = 2\n",
    "\n",
    "print('EXPERIMENTING ON FEATURES COMBINATIONS WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SHIFTS:',shifts,', AND SUBTOPIC LVL:',subtopic_lvl)\n",
    "for i in range(1,len(all_features)+1):\n",
    "    print('------ALL COMBINATIONS OF LENGTH',i,'------')\n",
    "    features_combinations = combinations(all_features,i)\n",
    "    for feature_comb in features_combinations:\n",
    "        feature_comb = list(feature_comb)\n",
    "\n",
    "        DT_scores, NB_scores = run_model(iterations,feature_comb,shifts,split,subtopic_lvl)\n",
    "        \n",
    "        print('-> Features =',feature_comb)\n",
    "        print('----- DT:')\n",
    "        get_avg_eval(DT_scores)\n",
    "        print()\n",
    "        # print('----- SVM:')\n",
    "        # get_avg_eval(SVM_scores)\n",
    "        print()\n",
    "        print('----- NB:')\n",
    "        get_avg_eval(NB_scores)\n",
    "        print()\n",
    "        print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fba27d2",
   "metadata": {},
   "source": [
    "## GridSearch for combinations of features, context lvl, subtopic lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4179fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON ALL PARAMETERS (combinations of features, context lvl (shifts), subtopic lvl) WITH SPLIT: 0.3 (of testing), ITERATIONS: 10\n",
      "------FEATURES: ['pause'] ------\n",
      "------SHIFTS: [-10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ------\n",
      "------SUBTOPIC LVL: 0 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5233619344773791, 0.5031118776244751, 0.5547329250329482, 0.5772557172557172, 0.5659848365187174, 0.5385362694300518, 0.5791221542031769, 0.551570423687224, 0.5617176297329768, 0.5434145282131094]\n",
      "-> pk: [0.45842433697347895, 0.4361127774445111, 0.4862004806574153, 0.4907692307692308, 0.4765834781235192, 0.46377104922279794, 0.5088224702916817, 0.49799607394078194, 0.4771925745068403, 0.46002388794382715]\n",
      "-> k-kappa: [0.004865370229170394, 0.057704898741927545, -0.0016739910559795108, -0.02758593756725326, 0.05374553172494793, 0.031682726798075024, -0.05921612210242258, -0.06650699292914379, 0.04474415963341396, 0.039273906957996284]\n",
      "\n",
      "-> windiff - mean: 0.5498808296175776 , - var: 0.0005657094155218732\n",
      "-> pk - mean: 0.47558963598740844 , - var: 0.00046534203889066704\n",
      "-> k-kappa - mean: 0.007703355043073199 , - var: 0.0020989425274152576\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5480889235569423, 0.5715731853629274, 0.5456236917590511, 0.5748440748440748, 0.6196493444953404, 0.6423656088082902, 0.5941663665826431, 0.5787665630623262, 0.6656977870790218, 0.633826776213399]\n",
      "-> pk: [0.4607254290171607, 0.46295740851829636, 0.4492208698348709, 0.46095634095634097, 0.47014689622492495, 0.5213730569948186, 0.4790141239547073, 0.5010633077048913, 0.5356353912335775, 0.5138079554091716]\n",
      "-> k-kappa: [-0.003659063004757745, 0.013731196609312874, 0.017248031592061428, 0.04604600220061298, 0.052809568581795335, -0.007503797570704792, 0.004265903957885839, -0.08612683362135184, -0.025756297289159603, -0.02018200661605971]\n",
      "\n",
      "-> windiff - mean: 0.5974602321764017 , - var: 0.0016838027331305086\n",
      "-> pk - mean: 0.48549007798487603 , - var: 0.0009069209156095477\n",
      "-> k-kappa - mean: -0.0009127295160365238 , - var: 0.0015514688691394656\n",
      "\n",
      "------SUBTOPIC LVL: 1 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5264307408797734, 0.5551896733403583, 0.5561959654178674, 0.5347239705089013, 0.5117726873653125, 0.581988864957126, 0.5665832531280077, 0.5798375282993741, 0.5278897365769397, 0.5346034738117679]\n",
      "-> pk: [0.44039859400061426, 0.47747629083245524, 0.44557243908828925, 0.4684768926452077, 0.4519913799984037, 0.4826268947860365, 0.474995187680462, 0.4863164202956452, 0.45375701741759034, 0.45243705399219064]\n",
      "-> k-kappa: [0.09325111447948066, 0.0168486091538999, 0.1032157080575877, 0.02377395561194302, 0.04559321599688629, 0.02712180476935766, 0.03661625123650143, 0.024363645100121508, 0.06072615732210536, 0.04906454086164979]\n",
      "\n",
      "-> windiff - mean: 0.5475215894285428 , - var: 0.0005742865132069086\n",
      "-> pk - mean: 0.46340481707368947 , - var: 0.00027149080719098993\n",
      "-> k-kappa - mean: 0.048057500258953334 , - var: 0.0008829735638999603\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4531276661092721, 0.48442439409905164, 0.49701991092481007, 0.49383204459629565, 0.49305610982520554, 0.4886820823342951, 0.5396727622714148, 0.45848315354907443, 0.507341298402188, 0.46364615591759795]\n",
      "-> pk: [0.4052486093574037, 0.4122102212855637, 0.41580429656798534, 0.4284840855961158, 0.4300822092744832, 0.4152883325882879, 0.44057747834456207, 0.40774404048475166, 0.4214049229883403, 0.40904806786050896]\n",
      "-> k-kappa: [0.08350131685616034, 0.09592894771273677, 0.08877730997554621, 0.03687791777111246, 0.03941785655927208, 0.07186738568201391, 0.0408343384326399, 0.06731610010485072, 0.06722422055517073, 0.06865039778364292]\n",
      "\n",
      "-> windiff - mean: 0.48792855780292055 , - var: 0.0006531920821609063\n",
      "-> pk - mean: 0.4185892264348003 , - var: 0.00012970839244265706\n",
      "-> k-kappa - mean: 0.0660395791433146 , - var: 0.00043928071016743046\n",
      "\n",
      "------SUBTOPIC LVL: 2 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5527816140798187, 0.5539168457718817, 0.5883305680651023, 0.5047147249743765, 0.5301195924996309, 0.5340487804878049, 0.5738536340011736, 0.5716359746313135, 0.5648177834776104, 0.5335825346959876]\n",
      "-> pk: [0.44874110273026663, 0.46053509227006595, 0.49296831792683893, 0.4386744106593782, 0.44625719769673705, 0.4509658536585366, 0.46198340179394753, 0.48227248414457097, 0.46083146307577216, 0.45500457311011255]\n",
      "-> k-kappa: [0.08958782606737335, 0.072734371136186, 0.014307080638709106, 0.08397475713900332, 0.08141755652073798, 0.06949040531162515, 0.07981025990260805, 0.03275959411445795, 0.06559372218600482, 0.06650628450793379]\n",
      "\n",
      "-> windiff - mean: 0.55078020526847 , - var: 0.0006347626190259573\n",
      "-> pk - mean: 0.4598233897066227 , - var: 0.0002738390439701252\n",
      "-> k-kappa - mean: 0.06561818575246395 , - var: 0.0005712758338083626\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5008675944615603, 0.5105610316460387, 0.4780358694793395, 0.46569866757772466, 0.46331020227373393, 0.4678634146341463, 0.5549082068907704, 0.4921295942538397, 0.4641801147091304, 0.44156360599673916]\n",
      "-> pk: [0.42459010588193635, 0.4174757281553398, 0.422770008690843, 0.413255893406218, 0.4123357448693341, 0.4114731707317073, 0.45636683711962445, 0.4269504088026286, 0.41206227067079904, 0.41511909969380045]\n",
      "-> k-kappa: [0.0783344987117503, 0.10130908237693839, 0.06271528824263504, 0.06600133833161437, 0.07226374871733209, 0.06109789309797322, 0.03773703892071112, 0.05131318293813705, 0.09145533723894432, 0.017240288793276597]\n",
      "\n",
      "-> windiff - mean: 0.48391183019230233 , - var: 0.0010374036267258445\n",
      "-> pk - mean: 0.4212399268022231 , - var: 0.0001838173489878086\n",
      "-> k-kappa - mean: 0.06394676973693125 , - var: 0.0006078610377913487\n",
      "\n",
      "\n",
      "------SHIFTS: [-9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9] ------\n",
      "------SUBTOPIC LVL: 0 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5577486214109146, 0.5746592781189157, 0.5465389608111427, 0.5886635844042375, 0.5079715383737301, 0.6245736239273275, 0.5285305630834086, 0.5699681707545403, 0.5484854563691073, 0.6304552363031048]\n",
      "-> pk: [0.47693477847499527, 0.4886550846188408, 0.47801985755885346, 0.5047144053296443, 0.44925992161637684, 0.505942336002298, 0.4454983438723276, 0.4870997940460588, 0.4736208625877633, 0.5081059564304842]\n",
      "-> k-kappa: [0.028596736085619797, 0.011617431600763844, 0.00667376424301002, 0.008298817856821333, 0.025667186042233208, 0.027034057223283548, 0.07687059358653629, 0.005129146673492095, 0.01994053172497394, 0.021225948742922236]\n",
      "\n",
      "-> windiff - mean: 0.567759503355643 , - var: 0.0015203992795663121\n",
      "-> pk - mean: 0.4817851340537643 , - var: 0.0004840587311194709\n",
      "-> k-kappa - mean: 0.023105421377965632 , - var: 0.00043341658521581596\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.6603156493629968, 0.6453497079526733, 0.5967091183384206, 0.49987258363973935, 0.5989878619535025, 0.6251122042296506, 0.5368488407106293, 0.6451226362104475, 0.6316148445336008, 0.6253166389230658]\n",
      "-> pk: [0.543259174748051, 0.5450801258050022, 0.5211030417850753, 0.4371109250427755, 0.5029869487462425, 0.5009514918674375, 0.4438798554652213, 0.5181052237408725, 0.5017853560682046, 0.5065860895997684]\n",
      "-> k-kappa: [-0.07346154163700289, -0.0965660283863659, -0.12125294476344935, -0.02629154293957705, -0.06654539355062722, 0.017673114932289038, 0.028986081801437164, -0.0367034331584739, -0.008179287154313356, -0.02651296908888781]\n",
      "\n",
      "-> windiff - mean: 0.6065250085854726 , - var: 0.0026223716280302975\n",
      "-> pk - mean: 0.5020848232868651 , - var: 0.0013104604671183512\n",
      "-> k-kappa - mean: -0.04088539439449713 , - var: 0.0023440849600349385\n",
      "\n",
      "------SUBTOPIC LVL: 1 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5573606790336828, 0.5594733656174334, 0.5596878960709759, 0.5823044551872848, 0.5453035490322362, 0.5762557077625571, 0.5439683920545164, 0.5697457207121345, 0.5473378982671884, 0.5184241219923107]\n",
      "-> pk: [0.47762799093597574, 0.4780190677966102, 0.4703738910012674, 0.4640211456195875, 0.4583573438188536, 0.4769786910197869, 0.46973321734087287, 0.47058823529411764, 0.4569591950810509, 0.44533241176724697]\n",
      "-> k-kappa: [0.028448204532830985, 0.029884348456396048, 0.04832768576609499, 0.07326395219327742, 0.057384520326617804, 0.041562274806857674, 0.032118284817559614, 0.05642283498519342, 0.06636580924642614, 0.07698243566448615]\n",
      "\n",
      "-> windiff - mean: 0.555986178573032 , - var: 0.0003405366164836528\n",
      "-> pk - mean: 0.46679911896753695 , - var: 0.0001132383401771544\n",
      "-> k-kappa - mean: 0.05107603507957403 , - var: 0.0003204639285762631\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5740676729269886, 0.5037832929782082, 0.5291904309252218, 0.5003651792856397, 0.44642554489678316, 0.5055555555555555, 0.4911918225315354, 0.5095497693568678, 0.5427263834544438, 0.5154434316817141]\n",
      "-> pk: [0.44947574605369284, 0.42418280871670705, 0.4354404309252218, 0.41425242583382604, 0.3979187146198434, 0.4337138508371385, 0.40397999130056544, 0.4060081582859975, 0.4358580212409167, 0.44416605468918746]\n",
      "-> k-kappa: [0.061483242042853575, 0.0664620446306715, 0.059267712558026986, 0.10606002180655381, 0.059624989364131666, 0.037607518018241665, 0.10532651573944604, 0.11145751258389347, 0.06322608741345805, 0.01232371499639378]\n",
      "\n",
      "-> windiff - mean: 0.5118299083592959 , - var: 0.0011207769690691656\n",
      "-> pk - mean: 0.4244996202503097 , - var: 0.0003243146005761801\n",
      "-> k-kappa - mean: 0.06828393591536705 , - var: 0.000996350249267759\n",
      "\n",
      "------SUBTOPIC LVL: 2 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5578010065814943, 0.5244304393494875, 0.5431376477659787, 0.5605049779328749, 0.5612863135000776, 0.5505009477389656, 0.5474400286430362, 0.5369562000591891, 0.5607012123450986, 0.531296205027107]\n",
      "-> pk: [0.4843205574912892, 0.4459053207287479, 0.4668403125626127, 0.4800369496048445, 0.47129874164983687, 0.4800974817221771, 0.4874328678839957, 0.47584344480615565, 0.4853746179937536, 0.46250205355676033]\n",
      "-> k-kappa: [0.016825987425322667, 0.07568340354044643, 0.03640749831164171, 0.019387661886376424, 0.04619569328504908, 0.015880724128555443, -0.014240102171136611, 0.01504358272593813, 0.005637313747777563, 0.05083446637978058]\n",
      "\n",
      "-> windiff - mean: 0.547405497894331 , - var: 0.00017482933852022248\n",
      "-> pk - mean: 0.47396523480001734 , - var: 0.0001637133026790011\n",
      "-> k-kappa - mean: 0.02676562292597514 , - var: 0.0006644160812554501\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5050716221447928, 0.4523887138252019, 0.5142055700260468, 0.43566321119436174, 0.4797265807052975, 0.5027271672275734, 0.45964912280701753, 0.5118748150340338, 0.5232562044531014, 0.5072285197962871]\n",
      "-> pk: [0.4415795586527294, 0.4067514216378717, 0.44063313965137246, 0.4080878579492969, 0.4173139661332919, 0.44416076747514605, 0.43344074471894023, 0.4465818289434744, 0.4496087584377204, 0.43818794151470347]\n",
      "-> k-kappa: [0.028618167516438524, 0.09380743054649558, 0.027532970439870894, 0.039782487145308285, 0.059416231415360996, 0.03320370197668114, 0.006878643022359341, 0.03248771757450668, 0.015029062135014743, 0.03670368215610632]\n",
      "\n",
      "-> windiff - mean: 0.4891791527213714 , - var: 0.0009159361350046284\n",
      "-> pk - mean: 0.4326345985114547 , - var: 0.00025535349657591813\n",
      "-> k-kappa - mean: 0.03734600939281425 , - var: 0.0005912083336474239\n",
      "\n",
      "\n",
      "------SHIFTS: [-8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 8] ------\n",
      "------SUBTOPIC LVL: 0 ------\n",
      "----- DT:\n",
      "-> windiff: [0.5545916841160634, 0.5723128243143069, 0.5751116071428571, 0.5653053286658888, 0.49751425647024416, 0.5542668072573901, 0.5396877869605142, 0.5298914173981778, 0.49461029707311727, 0.5867561683599419]\n",
      "-> pk: [0.45404576727490276, 0.4953298739807265, 0.4802455357142857, 0.4747569039284325, 0.4201272115806404, 0.4601316220048722, 0.47118457300275485, 0.4753505013104797, 0.4223700076734754, 0.489477503628447]\n",
      "-> k-kappa: [0.10521281786711992, -0.028555327208766763, 0.02885445436891133, 0.02889942128746413, 0.09851124448578004, 0.07387066461589298, -0.00018227345592565448, -0.03794663504428807, 0.09365019862140513, 0.0014904736287322557]\n",
      "\n",
      "-> windiff - mean: 0.5470048177758502 , - var: 0.0009996412531237844\n",
      "-> pk - mean: 0.4643019500099017 , - var: 0.0006624179734396316\n",
      "-> k-kappa - mean: 0.03638050391663253 , - var: 0.0028545990133478703\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.6094451091833682, 0.5563380281690141, 0.42332589285714284, 0.6743290548424737, 0.6406272846907443, 0.6573101116241864, 0.5962534435261708, 0.5615925448267255, 0.5806993824679358, 0.644121915820029]\n",
      "-> pk: [0.465973676338618, 0.47398072646404743, 0.34561011904761907, 0.5337611824192922, 0.5055929229419506, 0.5489946551285314, 0.49579430670339764, 0.43724258434912844, 0.4594950122410202, 0.49542815674891144]\n",
      "-> k-kappa: [0.07636434824000159, -0.012428464827575123, 0.14184670934981125, -0.04463456042560346, -0.03075998281046175, -0.06117429474842625, -0.040643715088297366, 0.0496154994136202, 0.03519946677658985, 0.012611109976706964]\n",
      "\n",
      "-> windiff - mean: 0.5944042768007791 , - var: 0.005240495218411191\n",
      "-> pk - mean: 0.47618733423825166 , - var: 0.0032433232718696438\n",
      "-> k-kappa - mean: 0.01259961158563659 , - var: 0.004079037114629759\n",
      "\n",
      "------SUBTOPIC LVL: 1 ------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [67], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m curr_subtopic_lvl \u001b[39m=\u001b[39m subtopic_lvls[l]\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m------SUBTOPIC LVL:\u001b[39m\u001b[39m'\u001b[39m,curr_subtopic_lvl,\u001b[39m'\u001b[39m\u001b[39m------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m DT_scores, NB_scores \u001b[39m=\u001b[39m run_model(iterations,feature_comb,curr_shifts,split,curr_subtopic_lvl)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m----- DT:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m get_avg_eval(DT_scores)\n",
      "Cell \u001b[1;32mIn [59], line 31\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(iterations, features, shift, split, subtopic_lvl)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[0;32m     29\u001b[0m     X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(features,shifts,split,subtopic_lvl)\n\u001b[1;32m---> 31\u001b[0m     DT_scores\u001b[39m.\u001b[39mappend(get_eval(DecTree(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;49;00m),y_test))\n\u001b[0;32m     32\u001b[0m     \u001b[39m# SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     NB_scores\u001b[39m.\u001b[39mappend(get_eval(naiveBayes(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;00m),y_test))\n",
      "Cell \u001b[1;32mIn [8], line 6\u001b[0m, in \u001b[0;36mDecTree\u001b[1;34m(X_train, X_test, y_train, tuning, best_criterion, best_max_depth, best_min_sample_leaf)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     clf \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m----> 6\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m y_predicted \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m y_predicted\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "iterations = 10\n",
    "\n",
    "subtopic_lvls = [0,1,2]\n",
    "shifts = [-10,-9,-8,-7,-6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6,7,8,9,10]\n",
    "\n",
    "print('EXPERIMENTING ON ALL PARAMETERS (combinations of features, context lvl (shifts), subtopic lvl) WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations)\n",
    "\n",
    "for i in range(1,len(all_features)+1):\n",
    "    features_combinations = combinations(all_features,i)\n",
    "    for feature_comb in features_combinations:\n",
    "        feature_comb = list(feature_comb)\n",
    "        print('------FEATURES:',feature_comb,'------')\n",
    "\n",
    "        j=0\n",
    "        while j<len(shifts)/2:\n",
    "            # get current shift\n",
    "            curr_shifts=[]\n",
    "            for k in range(j,len(shifts)-j):\n",
    "                curr_shifts.append(shifts[k])\n",
    "            print('------SHIFTS:',curr_shifts,'------')\n",
    "            \n",
    "            for l in range(len(subtopic_lvls)):\n",
    "                curr_subtopic_lvl = subtopic_lvls[l]\n",
    "                print('------SUBTOPIC LVL:',curr_subtopic_lvl,'------')\n",
    "\n",
    "                DT_scores, NB_scores = run_model(iterations,feature_comb,curr_shifts,split,curr_subtopic_lvl)\n",
    "                \n",
    "                print('----- DT:')\n",
    "                get_avg_eval(DT_scores)\n",
    "                print()\n",
    "                print('----- NB:')\n",
    "                get_avg_eval(NB_scores)\n",
    "                print()\n",
    "            j+=1\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ea1fa22",
   "metadata": {},
   "source": [
    "#### To read the file of the output of the code \n",
    "Please add the file in the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e501a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.10658901085020546', '0.10266616909897681', '-0.04659279581705039', '0.029284132290540693', '0.12114758465146477', '0.05468937802760812', '-0.04198029181586795', '0.0025401207878630134', '0.1894085782008286', '0.07655725318534783']\n"
     ]
    }
   ],
   "source": [
    "path = (os.path.realpath(os.path.join(os.getcwd(), (f\"simple_models.txt\"))))\n",
    "file = open(path, 'r')\n",
    "lines = file.readlines()\n",
    "\n",
    "combination=['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    if str(combination) in lines[i]:\n",
    "        DT_windiff=lines[i+2][12:-1].strip('][').split(', ')\n",
    "        DT_pk=lines[i+3][7:-1].strip('][').split(', ')\n",
    "        DT_kappa=lines[i+4][12:-1].strip('][').split(', ')\n",
    "\n",
    "        NB_windiff=lines[i+6][12:-1].strip('][').split(', ')\n",
    "        NB_pk=lines[i+7][7:-1].strip('][').split(', ')\n",
    "        NB_kappa=lines[i+8][12:-1].strip('][').split(', ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
