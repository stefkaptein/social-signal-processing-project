{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Test basic classification models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import model_trainer_and_tester as mtt\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "importlib.reload(sm)\n",
    "importlib.reload(mtt)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Jan's \"basic\" split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0_lvl/\"\n",
    "\n",
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,0.3)\n",
    "\n",
    "X_train = X_train[features_selected]\n",
    "X_test = X_test[features_selected]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nic's \"constant\" split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Represents the context that is being used for training and for evaluation\n",
    "shifts = [-2, -1, 1, 2]\n",
    "\n",
    "X_train_const, y_train_const = mtt.read_in_dataset(features_selected, shifts, to_read='train')\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_const, y_train_const)\n",
    "\n",
    "results_const = mtt.test_set_evaluate_multiple(clf, features_selected, shifts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_const.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test on commonly used models for topic segmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    int_y_pred = (np.array(y_pred))\n",
    "    int_y_true = (np.array(y_true))\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(int_y_true,int_y_pred,k))\n",
    "    print('- pk:',sm.get_pk(int_y_true,int_y_pred,k))\n",
    "    print('- kkappa:',sm.get_k_kappa(int_y_true,int_y_pred,k))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree classifier with/without hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train,tuning=False, best_criterion=None,best_max_depth=None,best_min_sample_leaf=None):\n",
    "    if tuning:\n",
    "        clf = DecisionTreeClassifier(criterion=best_criterion,max_depth=best_max_depth,min_samples_leaf=best_min_sample_leaf)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    return y_predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def DecTree_hyperparam(X,y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    std_slc = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),('dec_tree', clf)])\n",
    "\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy','log_loss']\n",
    "    max_depth = [2,5,10,15,20,30,50,100]\n",
    "    min_samples_leaf=[5,10,20,50,100]\n",
    "\n",
    "    parameters = dict(dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth,\n",
    "                      dec_tree__min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "\n",
    "    best_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    best_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "    best_min_samples_leaf = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf']\n",
    "\n",
    "    print('Best criterion:', best_criterion)\n",
    "    print('Best max_depth:', best_max_depth)\n",
    "    print('Best min_sample_leaf:', best_min_samples_leaf)\n",
    "\n",
    "    return best_criterion,best_max_depth,best_min_samples_leaf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_criterion,best_max_depth,best_min_sample_leaf = DecTree_hyperparam(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"-------------Normal DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,False)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,True,best_criterion,best_max_depth,best_min_sample_leaf)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM with/without hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SVM(X_train,X_test,y_train,tuning=False,best_gamma=None,best_C=None):\n",
    "    if tuning:\n",
    "        clf = SVC(gamma=best_gamma,C=best_C) \n",
    "    else:\n",
    "        clf = SVC() \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SVM_hyperparam(X,y):\n",
    "    param_grid = {\n",
    "        \"gamma\": [0.1, 1.0, 10],\n",
    "        \"C\": [0.1, 1.0, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_gamma = grid_search.best_estimator_.get_params()['gamma']\n",
    "    best_C = grid_search.best_estimator_.get_params()['C']\n",
    "    print('Best gamma:', best_gamma)\n",
    "    print('Best C:', best_C)\n",
    "\n",
    "    return best_gamma,best_C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_gamma,best_C = SVM_hyperparam(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"-------------Normal SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,False)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,True,best_gamma,best_C)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes for binary class with/without hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def naiveBayes(X_train,X_test,y_train,tuning=False,best_var_smoothing=None):\n",
    "\n",
    "    if tuning:\n",
    "        clf = GaussianNB(var_smoothing=best_var_smoothing) \n",
    "    else:\n",
    "        clf = GaussianNB() \n",
    "\n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def naiveBayes_hyperparam(X,y):\n",
    "        param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "        nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "        nbModel_grid.fit(X, y)\n",
    "\n",
    "        best_var_smoothing = nbModel_grid.best_estimator_.get_params()['var_smoothing']\n",
    "        print('Best var_smoothing:', best_var_smoothing)\n",
    "\n",
    "        return best_var_smoothing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_var_smoothing = naiveBayes_hyperparam(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"-------------Normal NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,False)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,True,best_var_smoothing)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiple runs of each algo with different splits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "\n",
    "    windiff = sm.get_windiff(np.array(y_true),np.array(y_pred),k)\n",
    "    pk = sm.get_pk(np.array(y_true),np.array(y_pred),k)\n",
    "    kappa = sm.get_k_kappa(np.array(y_true),np.array(y_pred),k)\n",
    "\n",
    "    return windiff,pk,kappa\n",
    "\n",
    "def get_avg_eval(eval):\n",
    "    windiffs = [row[0] for row in eval]\n",
    "    pks = [row[1] for row in eval]\n",
    "    kappas = [row[2] for row in eval]\n",
    "\n",
    "    print('-> windiff:',windiffs)\n",
    "    print('-> pk:',pks)\n",
    "    print('-> k-kappa:',kappas)\n",
    "\n",
    "    # print('-> windiff - mean:',statistics.mean(windiffs),', - var:',statistics.variance(windiffs))\n",
    "    # print('-> pk - mean:',statistics.mean(pks),', - var:',statistics.variance(pks))\n",
    "    # print('-> k-kappa - mean:',statistics.mean(kappas),', - var:',statistics.variance(kappas))\n",
    "\n",
    "def get_summary(DT_all,NB_all,features_selected):\n",
    "    print('-> Features =',features_selected)\n",
    "    print('----- DT:')\n",
    "    get_avg_eval(DT_all)\n",
    "    print('----- Naive Bayes:')\n",
    "    get_avg_eval(NB_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "split = 0.3\n",
    "iterations = 10\n",
    "\n",
    "print('EXPERIMENTING ON DTC AND NB WITH SPLIT',split,'(of testing) AND',iterations,'ITERATIONS PER MODEL TESTING')\n",
    "for i in range(1,len(all_features)+1):\n",
    "    print('------ALL COMBINATIONS OF LENGTH',i,'------')\n",
    "    features_combinations = combinations(all_features,i)\n",
    "    for feature_comb in features_combinations:\n",
    "        feature_comb = list(feature_comb)\n",
    "        DT_scores = []\n",
    "        NB_scores = []\n",
    "        for j in range(iterations):\n",
    "            X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,split)\n",
    "\n",
    "            X_train = X_train[feature_comb]\n",
    "            X_test = X_test[feature_comb]\n",
    "            \n",
    "            DT_scores.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "            NB_scores.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "        \n",
    "        get_summary(DT_scores,NB_scores,feature_comb)\n",
    "        print()\n",
    "    print()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### To read the file of the output of the code \n",
    "Please add the file in the project folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = (os.path.realpath(os.path.join(os.getcwd(), (f\"simple_models.txt\"))))\n",
    "file = open(path, 'r')\n",
    "lines = file.readlines()\n",
    "\n",
    "combination=['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    if str(combination) in lines[i]:\n",
    "        DT_windiff=lines[i+2][12:-1].strip('][').split(', ')\n",
    "        DT_pk=lines[i+3][7:-1].strip('][').split(', ')\n",
    "        DT_kappa=lines[i+4][12:-1].strip('][').split(', ')\n",
    "\n",
    "        NB_windiff=lines[i+6][12:-1].strip('][').split(', ')\n",
    "        NB_pk=lines[i+7][7:-1].strip('][').split(', ')\n",
    "        NB_kappa=lines[i+8][12:-1].strip('][').split(', ')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}