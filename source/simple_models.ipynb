{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Test basic classification models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import model_trainer_and_tester as mtt\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "importlib.reload(sm)\n",
    "importlib.reload(mtt)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de08adfa",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6781fdf",
   "metadata": {},
   "source": [
    "### Jan's \"basic\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29a92679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0_lvl/\"\n",
    "\n",
    "highest_lvl = 1\n",
    "\n",
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,highest_lvl,0.3)\n",
    "\n",
    "X_train = X_train[features_selected]\n",
    "X_test = X_test[features_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad55f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.0\n",
      "150.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_train))\n",
    "print(sum(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe08e24",
   "metadata": {},
   "source": [
    "### Nic's \"constant\" split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "579f4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents the context that is being used for training and for evaluation\n",
    "shifts = [-2, -1, 1, 2]\n",
    "\n",
    "X_train_const, y_train_const = mtt.read_in_dataset(features_selected, shifts, to_read='train')\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_const, y_train_const)\n",
    "\n",
    "results_const = mtt.test_set_evaluate_multiple(clf, features_selected, shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dd60c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pk         0.573975\n",
       "K-k       -0.070905\n",
       "Windiff    0.573975\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_const.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on commonly used models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb95e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    int_y_pred = (np.array(y_pred))\n",
    "    int_y_true = (np.array(y_true))\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(int_y_true,int_y_pred,k))\n",
    "    print('- pk:',sm.get_pk(int_y_true,int_y_pred,k))\n",
    "    print('- kkappa:',sm.get_k_kappa(int_y_true,int_y_pred,k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cbc4096",
   "metadata": {},
   "source": [
    "### Decision Tree classifier with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cf9d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train,tuning=False, best_criterion=None,best_max_depth=None,best_min_sample_leaf=None):\n",
    "    if tuning:\n",
    "        clf = DecisionTreeClassifier(criterion=best_criterion,max_depth=best_max_depth,min_samples_leaf=best_min_sample_leaf)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af133e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree_hyperparam(X,y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    std_slc = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),('dec_tree', clf)])\n",
    "\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy','log_loss']\n",
    "    max_depth = [2,5,10,15,20,30,50,100]\n",
    "    min_samples_leaf=[5,10,20,50,100]\n",
    "\n",
    "    parameters = dict(dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth,\n",
    "                      dec_tree__min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "\n",
    "    best_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    best_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "    best_min_samples_leaf = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf']\n",
    "\n",
    "    print('Best criterion:', best_criterion)\n",
    "    print('Best max_depth:', best_max_depth)\n",
    "    print('Best min_sample_leaf:', best_min_samples_leaf)\n",
    "\n",
    "    return best_criterion,best_max_depth,best_min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e92bf84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best criterion: log_loss\n",
      "Best max_depth: 30\n",
      "Best min_sample_leaf: 20\n"
     ]
    }
   ],
   "source": [
    "best_criterion,best_max_depth,best_min_sample_leaf = DecTree_hyperparam(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2c5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal DST\n",
      "176.0\n",
      "k = 58\n",
      "- windiff: 0.5367973856209151\n",
      "- pk: 0.46320261437908494\n",
      "- kkappa: 0.07036294315493824\n",
      "-------------Tuned DST\n",
      "0.0\n",
      "k = 58\n",
      "- windiff: 0.39771241830065357\n",
      "- pk: 0.39771241830065357\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,False)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,True,best_criterion,best_max_depth,best_min_sample_leaf)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,X_test,y_train,tuning=False,best_gamma=None,best_C=None):\n",
    "    if tuning:\n",
    "        clf = SVC(gamma=best_gamma,C=best_C) \n",
    "    else:\n",
    "        clf = SVC() \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1342bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_hyperparam(X,y):\n",
    "    param_grid = {\n",
    "        \"gamma\": [0.1, 1.0, 10],\n",
    "        \"C\": [0.1, 1.0, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_gamma = grid_search.best_estimator_.get_params()['gamma']\n",
    "    best_C = grid_search.best_estimator_.get_params()['C']\n",
    "    print('Best gamma:', best_gamma)\n",
    "    print('Best C:', best_C)\n",
    "\n",
    "    return best_gamma,best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1ad769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best gamma: 0.1\n",
      "Best C: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_gamma,best_C = SVM_hyperparam(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal SVM\n",
      "0.0\n",
      "k = 58\n",
      "- windiff: 0.39771241830065357\n",
      "- pk: 0.39771241830065357\n",
      "- kkappa: 0.0\n",
      "-------------Tuned SVM\n",
      "0.0\n",
      "k = 58\n",
      "- windiff: 0.39771241830065357\n",
      "- pk: 0.39771241830065357\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,False)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,True,best_gamma,best_C)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405deb78",
   "metadata": {},
   "source": [
    "### Naive Bayes for binary class with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e84d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train,X_test,y_train,tuning=False,best_var_smoothing=None):\n",
    "\n",
    "    if tuning:\n",
    "        clf = GaussianNB(var_smoothing=best_var_smoothing) \n",
    "    else:\n",
    "        clf = GaussianNB() \n",
    "\n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f660b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_hyperparam(X,y):\n",
    "        param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "        nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "        nbModel_grid.fit(X, y)\n",
    "\n",
    "        best_var_smoothing = nbModel_grid.best_estimator_.get_params()['var_smoothing']\n",
    "        print('Best var_smoothing:', best_var_smoothing)\n",
    "\n",
    "        return best_var_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc781deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Best var_smoothing: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_var_smoothing = naiveBayes_hyperparam(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6b72eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal NB\n",
      "167.0\n",
      "k = 48\n",
      "- windiff: 0.4680751799520128\n",
      "- pk: 0.3826312983204479\n",
      "- kkappa: 0.17552406762815045\n",
      "-------------Tuned NB\n",
      "37.0\n",
      "k = 48\n",
      "- windiff: 0.42721940815782455\n",
      "- pk: 0.4073580378565716\n",
      "- kkappa: 0.039813012811309854\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,False)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)\n",
    "\n",
    "print(\"-------------Tuned NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,True,best_var_smoothing)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c46a4f6",
   "metadata": {},
   "source": [
    "## Multiple runs of each algo with different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ce49c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    return sm.get_windiff(np.array(y_true),np.array(y_pred),k),sm.get_pk(np.array(y_true),np.array(y_pred),k),sm.get_k_kappa(np.array(y_true),np.array(y_pred),k)\n",
    "\n",
    "def get_avg_eval(eval):\n",
    "    print('- windiff:',sum([row[0] for row in eval])/len([row[0] for row in eval]))\n",
    "    print('- pk:',sum([row[1] for row in eval])/len([row[1] for row in eval]))\n",
    "    print('- k-kappa:',sum([row[2] for row in eval])/len([row[2] for row in eval]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5b8ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "split = 0.3\n",
    "\n",
    "iterations = 2\n",
    "\n",
    "DT_y_predicted=[]\n",
    "SVM_y_predicted=[]\n",
    "NB_y_predicted = []\n",
    "for i in range(iterations):\n",
    "    X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,split)\n",
    "\n",
    "    X_train = X_train[features_selected]\n",
    "    X_test = X_test[features_selected]\n",
    "    \n",
    "    DT_y_predicted.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "    SVM_y_predicted.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\n",
    "    NB_y_predicted.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67e9e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Parameters: nbr iterations = 2 , split = 0.3 , features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
      "----- DT:\n",
      "- windiff: 0.5693945206070412\n",
      "- pk: 0.47180533668419716\n",
      "- k-kappa: 0.06985474190961595\n",
      "----- SVM:\n",
      "- windiff: 0.3772829977404971\n",
      "- pk: 0.3772829977404971\n",
      "- k-kappa: 0.0\n",
      "----- Naive Bayes:\n",
      "- windiff: 0.4734117470534435\n",
      "- pk: 0.4253689385185653\n",
      "- k-kappa: 0.044894907236507776\n"
     ]
    }
   ],
   "source": [
    "print('-> Parameters: nbr iterations =',iterations,', split =',split,', features =',features_selected)\n",
    "print('----- DT:')\n",
    "get_avg_eval(DT_y_predicted)\n",
    "print('----- SVM:')\n",
    "get_avg_eval(SVM_y_predicted)\n",
    "print('----- Naive Bayes:')\n",
    "get_avg_eval(NB_y_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
