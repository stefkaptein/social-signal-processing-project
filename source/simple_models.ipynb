{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Test basic classification models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0) \n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a92679",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0/\"\n",
    "\n",
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,0.3)\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "X_train = X_train[features_selected]\n",
    "X_test = X_test[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on commonly used models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb95e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    int_y_pred = (np.array(y_pred))\n",
    "    int_y_true = (np.array(y_true))\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(int_y_true,int_y_pred,k))\n",
    "    print('- pk:',sm.get_pk(int_y_true,int_y_pred,k))\n",
    "    print('- kkappa:',sm.get_k_kappa(int_y_true,int_y_pred,k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cbc4096",
   "metadata": {},
   "source": [
    "### Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf9d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    # # get importance\n",
    "    # importance = clf.feature_importances_\n",
    "    # # summarize feature importance\n",
    "    # for i,v in enumerate(importance):\n",
    "    #     print('Feature:',features_selected[i],'->',v)\n",
    "    # # plot feature importance\n",
    "    # plt.bar(features_selected, importance)\n",
    "    # plt.title('Feature Importance')\n",
    "    # plt.show()\n",
    "\n",
    "    # # plot tree\n",
    "    # plt.figure(figsize=(15,10))  # set plot size (denoted in inches)\n",
    "    # tree.plot_tree(clf, max_depth=3, fontsize=10,feature_names=features_selected)\n",
    "    # plt.show()\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d2c5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.0\n",
      "k = 54\n",
      "- windiff: 0.5154753643303261\n",
      "- pk: 0.4587786259541985\n",
      "- kkappa: 0.05070403514991029\n"
     ]
    }
   ],
   "source": [
    "DT_y_predicted = DecTree(X_train,X_test,y_train)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c80bba",
   "metadata": {},
   "source": [
    "### XGB Classifier for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc922337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_class(X_train, X_test, y_train):\n",
    "    \n",
    "    clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c01f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "k = 54\n",
      "- windiff: 0.4111727966689799\n",
      "- pk: 0.4074947952810548\n",
      "- kkappa: 0.005407708984989378\n"
     ]
    }
   ],
   "source": [
    "XGBc_y_predicted = XGB_class(X_train,X_test,y_train)\n",
    "print(sum(XGBc_y_predicted))\n",
    "print_eval(XGBc_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMc(X_train,X_test,y_train):\n",
    "    clf = SVC(kernel='linear',probability=True) \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "k = 54\n",
      "- windiff: 0.4076335877862595\n",
      "- pk: 0.4076335877862595\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "SVM_y_predicted = SVMc(X_train,X_test,y_train)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df80d3c",
   "metadata": {},
   "source": [
    "### Random Forest classifier for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7c64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFc(X_train,X_test,y_train):\n",
    "    model = RandomForestClassifier().fit(X_train,y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a09f5463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "k = 54\n",
      "- windiff: 0.41512838306731437\n",
      "- pk: 0.41512838306731437\n",
      "- kkappa: -0.014938850491822761\n"
     ]
    }
   ],
   "source": [
    "RFc_y_predicted = RFc(X_train,X_test,y_train)\n",
    "print(sum(RFc_y_predicted))\n",
    "print_eval(RFc_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f40b2a8",
   "metadata": {},
   "source": [
    "### Logistic Regressor for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b88a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train,X_test,y_train):\n",
    "    model = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c49ed00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "k = 54\n",
      "- windiff: 0.4076335877862595\n",
      "- pk: 0.4076335877862595\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "LR_y_predicted = LR(X_train,X_test,y_train)\n",
    "print(sum(LR_y_predicted))\n",
    "print_eval(LR_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405deb78",
   "metadata": {},
   "source": [
    "### Naive Bayes for binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e84d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train,X_test,y_train):\n",
    "    param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "    }\n",
    "    nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "    nbModel_grid.fit(X_train, y_train)\n",
    "\n",
    "    best_var_smoothing = nbModel_grid.best_estimator_.get_params()['var_smoothing']\n",
    "    print('Best var_smoothing:', best_var_smoothing)\n",
    "\n",
    "    clf = GaussianNB(var_smoothing=best_var_smoothing) \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6b72eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "45.0\n",
      "k = 54\n",
      "- windiff: 0.44802220680083277\n",
      "- pk: 0.4178348369188064\n",
      "- kkappa: 0.02655901544051302\n"
     ]
    }
   ],
   "source": [
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c46a4f6",
   "metadata": {},
   "source": [
    "## Multiple runs of each algo with different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce49c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_fixedf0/\"\n",
    "\n",
    "def split_data(split,features_selected):\n",
    "    X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,split)\n",
    "\n",
    "    def filter(data):\n",
    "        data['similarity'] = data['similarity'][2:-2]\n",
    "        data['similarity'] = pd.to_numeric(data['similarity'])\n",
    "\n",
    "        data.fillna(0,inplace=True)\n",
    "\n",
    "        data = data[features_selected]\n",
    "        \n",
    "        return data\n",
    "\n",
    "    X_train = filter(X_train)\n",
    "    X_test = filter(X_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af41263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    return sm.get_windiff(np.array(y_true),np.array(y_pred),k),sm.get_pk(np.array(y_true),np.array(y_pred),k),sm.get_k_kappa(np.array(y_true),np.array(y_pred),k)\n",
    "\n",
    "def get_avg_eval(eval):\n",
    "    print('- windiff:',sum([row[0] for row in eval])/len([row[0] for row in eval]))\n",
    "    print('- pk:',sum([row[1] for row in eval])/len([row[1] for row in eval]))\n",
    "    print('- k-kappa:',sum([row[2] for row in eval])/len([row[2] for row in eval]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5b8ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "\n",
    "DT_y_predicted=[]\n",
    "XGBc_y_predicted=[]\n",
    "SVM_y_predicted=[]\n",
    "RFc_y_predicted=[]\n",
    "LR_y_predicted=[]\n",
    "for i in range(iterations):\n",
    "    X_train, y_train, X_test, y_test = split_data(split,features_selected)\n",
    "    \n",
    "    DT_y_predicted.append(get_eval(DecTree(X_train,X_test,y_train),y_test))\n",
    "    RFc_y_predicted.append(get_eval(RFc(X_train,X_test,y_train),y_test))\n",
    "    XGBc_y_predicted.append(get_eval(XGB_class(X_train,X_test,y_train),y_test))\n",
    "    SVM_y_predicted.append(get_eval(SVMc(X_train,X_test,y_train),y_test))\n",
    "    LR_y_predicted.append(get_eval(LR(X_train,X_test,y_train),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67e9e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Parameters: nbr iterations = 1 , split = 0.3 , features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
      "----- DT:\n",
      "- windiff: 0.5326856349757113\n",
      "- pk: 0.47300485773768214\n",
      "- k-kappa: 0.022641456563010094\n",
      "----- RF:\n",
      "- windiff: 0.41512838306731437\n",
      "- pk: 0.41512838306731437\n",
      "- k-kappa: -0.014938850491822761\n",
      "----- XGB:\n",
      "- windiff: 0.4111727966689799\n",
      "- pk: 0.4074947952810548\n",
      "- k-kappa: 0.005407708984989378\n",
      "----- SVM:\n",
      "- windiff: 0.4076335877862595\n",
      "- pk: 0.4076335877862595\n",
      "- k-kappa: 0.0\n",
      "----- LR:\n",
      "- windiff: 0.4076335877862595\n",
      "- pk: 0.4076335877862595\n",
      "- k-kappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('-> Parameters: nbr iterations =',iterations,', split =',split,', features =',features_selected)\n",
    "print('----- DT:')\n",
    "get_avg_eval(DT_y_predicted)\n",
    "print('----- RF:')\n",
    "get_avg_eval(RFc_y_predicted)\n",
    "print('----- XGB:')\n",
    "get_avg_eval(XGBc_y_predicted)\n",
    "print('----- SVM:')\n",
    "get_avg_eval(SVM_y_predicted)\n",
    "print('----- LR:')\n",
    "get_avg_eval(LR_y_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
