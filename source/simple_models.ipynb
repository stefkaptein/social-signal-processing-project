{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83a83341",
   "metadata": {},
   "source": [
    "# Test basic classification models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d435b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.load_data as ld\n",
    "import model.scoring_metrics as sm\n",
    "import model_trainer_and_tester as mtt\n",
    "import importlib\n",
    "importlib.reload(sm)\n",
    "importlib.reload(ld)\n",
    "importlib.reload(sm)\n",
    "importlib.reload(mtt)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de08adfa",
   "metadata": {},
   "source": [
    "## Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77f44018",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002 Bns003 Bro003 Bro004 Bro005 Bro007 Bro008 Bro010 Bro011 Bro012 Bro013 Bro014 Bro015 Bro016 Bro017 Bro018 Bro019 Bro021 Bro022 Bro023 Bro024 Bro025 Bro026 Bro027 Bro028 Bsr001 Btr001 Btr002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_f0_stds_fixed/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split=0.3\n",
    "\n",
    "# Represents the context that is being used for training and for evaluation\n",
    "shifts = [-3,-2,-1, 1,2,3]\n",
    "\n",
    "subtopic_lvl = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29ab19a7",
   "metadata": {},
   "source": [
    "### Basic random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "894a222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ld.train_test_split(datasets,results_merged_path,split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6781fdf",
   "metadata": {},
   "source": [
    "### Basic random split + context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29a92679",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../topic_boundaries/Bro016_topic_boundaries_lvl_3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(features_selected,shifts,split,subtopic_lvl)\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:317\u001b[0m, in \u001b[0;36mread_in_dataset_all_together\u001b[1;34m(features, shifts, test_split, subtopic_lvl)\u001b[0m\n\u001b[0;32m    314\u001b[0m test_selected_meetings \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(dataset_list) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(train_selected_meetings))\n\u001b[0;32m    316\u001b[0m base_df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../results_merged_f0_stds_fixed/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m train_selected_meetings[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 317\u001b[0m segment_boundaries_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../topic_boundaries/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m train_selected_meetings[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_topic_boundaries_lvl_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(subtopic_lvl)\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    319\u001b[0m base_y_train \u001b[39m=\u001b[39m []\n\u001b[0;32m    320\u001b[0m \u001b[39mfor\u001b[39;00m segId \u001b[39min\u001b[39;00m base_df_train[\u001b[39m'\u001b[39m\u001b[39msegID\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../topic_boundaries/Bro016_topic_boundaries_lvl_3.csv'"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(features_selected,shifts,split,subtopic_lvl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe08e24",
   "metadata": {},
   "source": [
    "### Constant split + context (to compare with biLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "579f4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const, y_train_const = mtt.read_in_dataset(features_selected, shifts, to_read='train')\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_const, y_train_const)\n",
    "\n",
    "results_const = mtt.test_set_evaluate_multiple(clf, features_selected, shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dd60c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pk         0.572100\n",
       "K-k       -0.066113\n",
       "Windiff    0.572100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_const.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "888c6482",
   "metadata": {},
   "source": [
    "## Test on commonly used models for topic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb95e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "    print('k =',k)\n",
    "\n",
    "    print('- windiff:',sm.get_windiff(np.array(y_true),np.array(y_pred),k))\n",
    "    print('- pk:',sm.get_pk(np.array(y_true),np.array(y_pred),k))\n",
    "    print('- kkappa:',sm.get_k_kappa(np.array(y_true),np.array(y_pred),k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cbc4096",
   "metadata": {},
   "source": [
    "### Decision Tree classifier with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf9d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree(X_train, X_test, y_train,tuning=False, best_criterion=None,best_max_depth=None,best_min_sample_leaf=None):\n",
    "    if tuning:\n",
    "        clf = DecisionTreeClassifier(criterion=best_criterion,max_depth=best_max_depth,min_samples_leaf=best_min_sample_leaf)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af133e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecTree_hyperparam(X,y):\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    std_slc = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('std_slc', std_slc),('dec_tree', clf)])\n",
    "\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy','log_loss']\n",
    "    max_depth = [2,5,10,15,20,30,50,100]\n",
    "    min_samples_leaf=[5,10,20,50,100]\n",
    "\n",
    "    parameters = dict(dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth,\n",
    "                      dec_tree__min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters)\n",
    "    clf_GS.fit(X, y)\n",
    "\n",
    "    best_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    best_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "    best_min_samples_leaf = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf']\n",
    "\n",
    "    print('Best criterion:', best_criterion)\n",
    "    print('Best max_depth:', best_max_depth)\n",
    "    print('Best min_sample_leaf:', best_min_samples_leaf)\n",
    "\n",
    "    return best_criterion,best_max_depth,best_min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e92bf84a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecTree_hyperparam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_criterion,best_max_depth,best_min_sample_leaf \u001b[39m=\u001b[39m DecTree_hyperparam(X_train,y_train)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Tuned DST\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m DT_y_predicted \u001b[39m=\u001b[39m DecTree(X_train,X_test,y_train,\u001b[39mTrue\u001b[39;00m,best_criterion,best_max_depth,best_min_sample_leaf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecTree_hyperparam' is not defined"
     ]
    }
   ],
   "source": [
    "best_criterion,best_max_depth,best_min_sample_leaf = DecTree_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,True,best_criterion,best_max_depth,best_min_sample_leaf)\n",
    "print(sum(DT_y_predicted))\n",
    "print_eval(DT_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d2c5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal DST\n",
      "417 312\n",
      "k = 44\n",
      "- windiff: 0.5588575560375995\n",
      "- pk: 0.47736804049168474\n",
      "- kkappa: 0.03370331277192754\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal DST\")\n",
    "DT_y_predicted = DecTree(X_train,X_test,y_train,False)\n",
    "print(sum(DT_y_predicted),sum(y_test))\n",
    "print_eval(DT_y_predicted,y_test)\n",
    "indexes = [index for index in range(len(DT_y_predicted)) if (DT_y_predicted[index]==1)and(y_test[index]==1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c8885d3",
   "metadata": {},
   "source": [
    "### SVM with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2de33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,X_test,y_train,tuning=False,best_gamma=None,best_C=None):\n",
    "    if tuning:\n",
    "        clf = SVC(gamma=best_gamma,C=best_C) \n",
    "    else:\n",
    "        clf = SVC() \n",
    "    clf.fit(X_train, y_train) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_hyperparam(X,y):\n",
    "    param_grid = {\n",
    "        \"gamma\": [0.1, 1.0, 10],\n",
    "        \"C\": [0.1, 1.0, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_gamma = grid_search.best_estimator_.get_params()['gamma']\n",
    "    best_C = grid_search.best_estimator_.get_params()['C']\n",
    "    print('Best gamma:', best_gamma)\n",
    "    print('Best C:', best_C)\n",
    "\n",
    "    return best_gamma,best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ad769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best gamma: 0.1\n",
      "Best C: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_gamma,best_C = SVM_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,True,best_gamma,best_C)\n",
    "print(sum(SVM_y_predicted))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98c7d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal SVM\n",
      "0.0 288.0\n",
      "k = 46\n",
      "- windiff: 0.4033554051037869\n",
      "- pk: 0.4033554051037869\n",
      "- kkappa: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal SVM\")\n",
    "SVM_y_predicted = SVM(X_train,X_test,y_train,False)\n",
    "print(sum(SVM_y_predicted),sum(y_test))\n",
    "print_eval(SVM_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405deb78",
   "metadata": {},
   "source": [
    "### Naive Bayes for binary class with/without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e84d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train,X_test,y_train,tuning=False,best_var_smoothing=None):\n",
    "\n",
    "    if tuning:\n",
    "        clf = GaussianNB(var_smoothing=best_var_smoothing) \n",
    "    else:\n",
    "        clf = GaussianNB() \n",
    "\n",
    "    clf.fit(X_train, np.ravel(y_train)) \n",
    "    y_predicted = clf.predict(X_test)\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes_hyperparam(X,y):\n",
    "        param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "        nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "        nbModel_grid.fit(X, y)\n",
    "\n",
    "        best_var_smoothing = nbModel_grid.best_estimator_.get_params()['var_smoothing']\n",
    "        print('Best var_smoothing:', best_var_smoothing)\n",
    "\n",
    "        return best_var_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc781deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naiveBayes_hyperparam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [70], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_var_smoothing \u001b[39m=\u001b[39m naiveBayes_hyperparam(X_train,y_train)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------Tuned NB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m NB_y_predicted \u001b[39m=\u001b[39m naiveBayes(X_train,X_test,y_train,\u001b[39mTrue\u001b[39;00m,best_var_smoothing)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'naiveBayes_hyperparam' is not defined"
     ]
    }
   ],
   "source": [
    "best_var_smoothing = naiveBayes_hyperparam(X_train,y_train)\n",
    "\n",
    "print(\"-------------Tuned NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,True,best_var_smoothing)\n",
    "print(sum(NB_y_predicted))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b72eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Normal NB\n",
      "216 98\n",
      "k = 121\n",
      "- windiff: 0.5901898734177216\n",
      "- pk: 0.4794720186542305\n",
      "- kkappa: 0.010325750790288572\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Normal NB\")\n",
    "NB_y_predicted = naiveBayes(X_train,X_test,y_train,False)\n",
    "print(sum(NB_y_predicted),sum(y_test))\n",
    "print_eval(NB_y_predicted,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c46a4f6",
   "metadata": {},
   "source": [
    "## Multiple runs of each algo with different random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ce49c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval(y_pred,y_true):\n",
    "    k = int(max(1,np.floor((len(y_true)+1)/(2*(sum(y_true)+1)))))\n",
    "\n",
    "    windiff = sm.get_windiff(np.array(y_true),np.array(y_pred),k)\n",
    "    pk = sm.get_pk(np.array(y_true),np.array(y_pred),k)\n",
    "    kappa = sm.get_k_kappa(np.array(y_true),np.array(y_pred),k)\n",
    "\n",
    "    return windiff,pk,kappa\n",
    "\n",
    "def get_avg_eval(eval):\n",
    "    windiffs = [row[0] for row in eval]\n",
    "    pks = [row[1] for row in eval]\n",
    "    kappas = [row[2] for row in eval]\n",
    "\n",
    "    print('-> windiff:',windiffs)\n",
    "    print('-> pk:',pks)\n",
    "    print('-> k-kappa:',kappas)\n",
    "    print()\n",
    "    print('-> windiff - mean:',statistics.mean(windiffs),', - var:',statistics.variance(windiffs))\n",
    "    print('-> pk - mean:',statistics.mean(pks),', - var:',statistics.variance(pks))\n",
    "    print('-> k-kappa - mean:',statistics.mean(kappas),', - var:',statistics.variance(kappas))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e9e6c8",
   "metadata": {},
   "source": [
    "### Test different context levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "subtopic_lvl = 2\n",
    "\n",
    "shifts = [-10,-9,-8,-7,-6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6,7,8,9,10]\n",
    "\n",
    "iterations = 1\n",
    "print('EXPERIMENTING ON CONTEXT LEVEL WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SUBTOPIC LVL:',subtopic_lvl,', AND FEATURES:',features_selected,)\n",
    "i=0\n",
    "while i<len(shifts)/2:\n",
    "    # get current shift\n",
    "    curr_shifts=[]\n",
    "    for j in range(i,len(shifts)-i):\n",
    "        curr_shifts.append(shifts[j])\n",
    "    \n",
    "    DT_scores = []\n",
    "    SVM_scores = []\n",
    "    NB_scores = []\n",
    "    for k in range(iterations):\n",
    "        X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(features_selected,curr_shifts,split,subtopic_lvl)\n",
    "        \n",
    "        DT_scores.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "        # SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\n",
    "        NB_scores.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "    \n",
    "    print('-> Context level =',len(curr_shifts)/2)\n",
    "    print('----- DT:')\n",
    "    get_avg_eval(DT_scores)\n",
    "    print()\n",
    "    # print('----- SVM:')\n",
    "    # get_avg_eval(SVM_scores)\n",
    "    print()\n",
    "    print('----- NB:')\n",
    "    get_avg_eval(NB_scores)\n",
    "    print()\n",
    "    print()\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9032ba3a",
   "metadata": {},
   "source": [
    "### Test different subtopic levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8924d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON SUBTOPIC LEVEL WITH SPLIT: 0.3 (of testing), ITERATIONS: 5 , SHIFTS: [-2, -1, 1, 2] , AND FEATURES: ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
      "-> Subtopic level = 0\n",
      "----- DT:\n",
      "-> windiff: [0.5010247241965726, 0.5488873661052404, 0.5195572229857732, 0.4815499638234585, 0.5218722492249991]\n",
      "-> pk: [0.42724458204334365, 0.4657554008727955, 0.4656959251142231, 0.41824101615885523, 0.43679436641279806]\n",
      "-> k-kappa: [0.0735877793581976, 0.07260134124398052, 0.008315120756543913, 0.0845347890168983, 0.08631362659916918]\n",
      "\n",
      "-> windiff - mean: 0.5145783052672087 , - var: 0.0006324184485146581\n",
      "-> pk - mean: 0.4427462581204031 , - var: 0.0004830854312545858\n",
      "-> k-kappa - mean: 0.0650705313949579 , - var: 0.0010451399163032228\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.421750316138316, 0.4992245825368774, 0.49177222242858737, 0.4573116810032961, 0.4026560526617934]\n",
      "-> pk: [0.3687698949112632, 0.42186316586720524, 0.44400282307492295, 0.40035372618377685, 0.37785602204447166]\n",
      "-> k-kappa: [0.09137861702750713, 0.06758989691868977, -0.006438312231092104, 0.09098567715420137, 0.0197421187458266]\n",
      "\n",
      "-> windiff - mean: 0.45454297095377405 , - var: 0.0017894349585152482\n",
      "-> pk - mean: 0.40256912641632797 , - var: 0.0009617611883365214\n",
      "-> k-kappa - mean: 0.05265159952302655 , - var: 0.0019417719294602463\n",
      "\n",
      "\n",
      "-> Subtopic level = 1\n",
      "----- DT:\n",
      "-> windiff: [0.5290766288202499, 0.5857089691105322, 0.5311626321172861, 0.5888799786153435, 0.5355785108098767]\n",
      "-> pk: [0.45468603752085623, 0.4810197245999256, 0.4634503920900102, 0.4819948829571925, 0.4574709112553281]\n",
      "-> k-kappa: [0.053333450014135586, 0.048044445686814465, 0.036692871900573576, 0.0490236021120281, 0.05279761256943441]\n",
      "\n",
      "-> windiff - mean: 0.5540813438946577 , - var: 0.0009260274032173378\n",
      "-> pk - mean: 0.4677243896846625 , - var: 0.00016845310280942208\n",
      "-> k-kappa - mean: 0.047978396456597225 , - var: 4.509033110347589e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4564359256094087, 0.49542240416821737, 0.4278213433344698, 0.45262916714400275, 0.5248262355516301]\n",
      "-> pk: [0.4143572213404957, 0.4363974692966133, 0.4092396863279918, 0.3953488372093023, 0.43431511846703275]\n",
      "-> k-kappa: [0.06024936427126422, 0.004972899296799854, 0.02273248532992469, 0.0749077385878422, 0.05049197127118664]\n",
      "\n",
      "-> windiff - mean: 0.4714270151615457 , - var: 0.001476700475847945\n",
      "-> pk - mean: 0.41793166652828717 , - var: 0.0003019286818902908\n",
      "-> k-kappa - mean: 0.04267089175140352 , - var: 0.0008070162401694245\n",
      "\n",
      "\n",
      "-> Subtopic level = 2\n",
      "----- DT:\n",
      "-> windiff: [0.5501186452865463, 0.554558935223697, 0.5760904425914047, 0.5345953919640348, 0.550710286780668]\n",
      "-> pk: [0.450636370173294, 0.46746717783644975, 0.47358082103912763, 0.45739674065748803, 0.47644437673763185]\n",
      "-> k-kappa: [0.09154248225187496, 0.056143469104847805, 0.052558969294050684, 0.06191776748490775, 0.021958597678387714]\n",
      "\n",
      "-> windiff - mean: 0.5532147403692702 , - var: 0.00022191070988417726\n",
      "-> pk - mean: 0.46510509728879823 , - var: 0.00011868985058065584\n",
      "-> k-kappa - mean: 0.05682425716281378 , - var: 0.0006163923412508078\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.47749334867333, 0.47426670042316177, 0.5025657472738935, 0.4644211857263276, 0.49323989793198003]\n",
      "-> pk: [0.41784712734594087, 0.4001229700893342, 0.4461994868505452, 0.4246979488620399, 0.42202079445481205]\n",
      "-> k-kappa: [0.07009747958379858, 0.11816757240513553, 0.023304120108127782, 0.049690396693065804, 0.08356337207805659]\n",
      "\n",
      "-> windiff - mean: 0.48239737600573857 , - var: 0.00023440606694971817\n",
      "-> pk - mean: 0.42217766552053443 , - var: 0.00027214687202707747\n",
      "-> k-kappa - mean: 0.06896458817363686 , - var: 0.0012729285982278405\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "split = 0.3\n",
    "shifts = [-2, -1, 1, 2]\n",
    "\n",
    "subtopic_lvls = [0,1,2]\n",
    "\n",
    "iterations = 5\n",
    "print('EXPERIMENTING ON SUBTOPIC LEVEL WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SHIFTS:',shifts,', AND FEATURES:',features_selected,)\n",
    "\n",
    "for i in range(len(subtopic_lvls)):\n",
    "    curr_subtopic_lvl = subtopic_lvls[i]\n",
    "    DT_scores = []\n",
    "    SVM_scores = []\n",
    "    NB_scores = []\n",
    "    for j in range(iterations):\n",
    "        X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(features_selected,shifts,split,curr_subtopic_lvl)        \n",
    "        DT_scores.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "        # SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\n",
    "        NB_scores.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "    \n",
    "    print('-> Subtopic level =',curr_subtopic_lvl)\n",
    "    print('----- DT:')\n",
    "    get_avg_eval(DT_scores)\n",
    "    print()\n",
    "    # print('----- SVM:')\n",
    "    # get_avg_eval(SVM_scores)\n",
    "    print()\n",
    "    print('----- NB:')\n",
    "    get_avg_eval(NB_scores)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59b09e6",
   "metadata": {},
   "source": [
    "### Test different combinations of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5b8ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENTING ON FEATURES COMBINATIONS WITH SPLIT: 0.3 (of testing), ITERATIONS: 2 , SHIFTS: [-2, -1, 1, 2] , AND SUBTOPIC LVL: 1\n",
      "------ALL COMBINATIONS OF LENGTH 1 ------\n",
      "-> Features = ['pause']\n",
      "----- DT:\n",
      "-> windiff: [0.5622854340362923, 0.5340374763141273]\n",
      "-> pk: [0.47218524486793245, 0.464804547687557]\n",
      "-> k-kappa: [0.0594864010078124, 0.03817162002451795]\n",
      "\n",
      "-> windiff - mean: 0.5481614551752099 , - var: 0.00039897355773660864\n",
      "-> pk - mean: 0.46849489627774477 , - var: 2.72373454342009e-05\n",
      "-> k-kappa - mean: 0.04882901051616517 , - var: 0.0002271599441829054\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.5265536327331325, 0.45368096006737313]\n",
      "-> pk: [0.4567715266587263, 0.400835146326058]\n",
      "-> k-kappa: [0.0043759265917455775, 0.07519984148327805]\n",
      "\n",
      "-> windiff - mean: 0.4901172964002528 , - var: 0.0026552132107254558\n",
      "-> pk - mean: 0.4288033364923921 , - var: 0.0015644393223604599\n",
      "-> k-kappa - mean: 0.03978788403751181 , - var: 0.0025080134602815172\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange']\n",
      "----- DT:\n",
      "-> windiff: [0.39705882352941174, 0.4136229990199281]\n",
      "-> pk: [0.39705882352941174, 0.4136229990199281]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> pk - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.39705882352941174, 0.4136229990199281]\n",
      "-> pk: [0.39705882352941174, 0.4136229990199281]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> pk - mean: 0.4053409112746699 , - var: 0.0001371859548403115\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5324642662530913, 0.5465580678637693]\n",
      "-> pk: [0.4672004023976192, 0.45457404320890593]\n",
      "-> k-kappa: [0.029505189336403087, 0.08246516729177422]\n",
      "\n",
      "-> windiff - mean: 0.5395111670584303 , - var: 9.931762192057446e-05\n",
      "-> pk - mean: 0.46088722280326255 , - var: 7.971247318120167e-05\n",
      "-> k-kappa - mean: 0.055985178314088654 , - var: 0.0014023796325166983\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4113258163222534, 0.3981571747539231]\n",
      "-> pk: [0.4113258163222534, 0.3981571747539231]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.40474149553808825 , - var: 8.670656037757845e-05\n",
      "-> pk - mean: 0.40474149553808825 , - var: 8.670656037757845e-05\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.49897610921501706, 0.4945207317618643]\n",
      "-> pk: [0.4504400934075804, 0.46092946280806907]\n",
      "-> k-kappa: [0.03705410705237311, -0.023748939658868377]\n",
      "\n",
      "-> windiff - mean: 0.4967484204884407 , - var: 9.925194125031057e-06\n",
      "-> pk - mean: 0.4556847781078247 , - var: 5.5013435209954e-05\n",
      "-> k-kappa - mean: 0.006652583696752366 , - var: 0.001848505244684707\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4002514819471888, 0.3988459990159682]\n",
      "-> pk: [0.4002514819471888, 0.3988459990159682]\n",
      "-> k-kappa: [0.0, 0.0032704021644514437]\n",
      "\n",
      "-> windiff - mean: 0.3995487404815785 , - var: 9.876911349762448e-07\n",
      "-> pk - mean: 0.3995487404815785 , - var: 9.876911349762448e-07\n",
      "-> k-kappa - mean: 0.0016352010822257219 , - var: 5.347765158624344e-06\n",
      "\n",
      "\n",
      "-> Features = ['f0_baseline_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5275095275095275, 0.5129823810542835]\n",
      "-> pk: [0.4805194805194805, 0.4536700192595763]\n",
      "-> k-kappa: [-0.018283729100434482, 0.037391591581407944]\n",
      "\n",
      "-> windiff - mean: 0.5202459542819056 , - var: 0.00010551899206605416\n",
      "-> pk - mean: 0.46709474988952837 , - var: 0.000360446784973549\n",
      "-> k-kappa - mean: 0.009553931240486731 , - var: 0.0015498706665129955\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4087024087024087, 0.3917897139596262]\n",
      "-> pk: [0.4087024087024087, 0.38815179399386546]\n",
      "-> k-kappa: [0.0, 0.009079378911669624]\n",
      "\n",
      "-> windiff - mean: 0.4002460613310175 , - var: 0.00014301962173127154\n",
      "-> pk - mean: 0.3984271013481371 , - var: 0.00021116388244949702\n",
      "-> k-kappa - mean: 0.004539689455834812 , - var: 4.1217560710835545e-05\n",
      "\n",
      "\n",
      "\n",
      "------ALL COMBINATIONS OF LENGTH 2 ------\n",
      "-> Features = ['pause', 'speakerChange']\n",
      "----- DT:\n",
      "-> windiff: [0.625154130702836, 0.5780664316199666]\n",
      "-> pk: [0.4953106901318985, 0.4835776581926146]\n",
      "-> k-kappa: [0.047622298665306755, 0.035445417654770175]\n",
      "\n",
      "-> windiff - mean: 0.6016102811614013 , - var: 0.001108625702459428\n",
      "-> pk - mean: 0.48944417416225655 , - var: 6.88320192441278e-05\n",
      "-> k-kappa - mean: 0.04153385816003846 , - var: 7.413821557238317e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4972536711131039, 0.4663945073297458]\n",
      "-> pk: [0.4248402645443336, 0.40642048617554277]\n",
      "-> k-kappa: [0.07239160195342516, 0.07751046598792205]\n",
      "\n",
      "-> windiff - mean: 0.48182408922142483 , - var: 0.0004761439947040608\n",
      "-> pk - mean: 0.4156303753599382 , - var: 0.00016964411757768727\n",
      "-> k-kappa - mean: 0.0749510339706736 , - var: 1.31013845018329e-05\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5255471979399607, 0.5179536447700253]\n",
      "-> pk: [0.4396218743647083, 0.4511828990032425]\n",
      "-> k-kappa: [0.10712551583087733, 0.06616251733938035]\n",
      "\n",
      "-> windiff - mean: 0.521750421354993 , - var: 2.8831024872318627e-05\n",
      "-> pk - mean: 0.44540238668397536 , - var: 6.682864534639742e-05\n",
      "-> k-kappa - mean: 0.08664401658512884 , - var: 0.000838983622707192\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.46029003184929185, 0.47295944918137783]\n",
      "-> pk: [0.411093040590906, 0.41975901685280814]\n",
      "-> k-kappa: [0.04877254824734451, 0.03913617894476837]\n",
      "\n",
      "-> windiff - mean: 0.46662474051533487 , - var: 8.02570677672804e-05\n",
      "-> pk - mean: 0.4154260287218571 , - var: 3.7549572285925614e-05\n",
      "-> k-kappa - mean: 0.04395436359605644 , - var: 4.642980666781592e-05\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5237683014038917, 0.5149293380087132]\n",
      "-> pk: [0.4603861643268471, 0.45570785959692556]\n",
      "-> k-kappa: [0.03873924635552089, 0.033420001641914644]\n",
      "\n",
      "-> windiff - mean: 0.5193488197063025 , - var: 3.906363695065302e-05\n",
      "-> pk - mean: 0.45804701196188635 , - var: 1.0943267573003098e-05\n",
      "-> k-kappa - mean: 0.036079623998717766 , - var: 1.4147182161613988e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.49715834242914675, 0.4923316686147416]\n",
      "-> pk: [0.44088975874139036, 0.4092374172068147]\n",
      "-> k-kappa: [0.007897508924640119, 0.09678968071145001]\n",
      "\n",
      "-> windiff - mean: 0.49474500552194417 , - var: 1.1648390055332218e-05\n",
      "-> pk - mean: 0.42506358797410254 , - var: 0.0005009353623107109\n",
      "-> k-kappa - mean: 0.05234359481804507 , - var: 0.00395090910248786\n",
      "\n",
      "\n",
      "-> Features = ['pause', 'f0_baseline_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.5179174867243492, 0.5787574117040475]\n",
      "-> pk: [0.4585762560808051, 0.4806098773616175]\n",
      "-> k-kappa: [0.036977557175158896, 0.04210330314071717]\n",
      "\n",
      "-> windiff - mean: 0.5483374492141984 , - var: 0.001850748235767656\n",
      "-> pk - mean: 0.46959306672121126 , - var: 0.00024274023337313402\n",
      "-> k-kappa - mean: 0.03954043015793803 , - var: 1.3136635851718457e-05\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.4670058301459393, 0.4119618458365558]\n",
      "-> pk: [0.416131308255041, 0.3945788678967333]\n",
      "-> k-kappa: [0.06566811229716217, 0.02189962355823541]\n",
      "\n",
      "-> windiff - mean: 0.4394838379912476 , - var: 0.001514920104325829\n",
      "-> pk - mean: 0.40535508807588716 , - var: 0.00023225384269920577\n",
      "-> k-kappa - mean: 0.04378386792769879 , - var: 0.0009578403032447794\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange', 'similarity']\n",
      "----- DT:\n",
      "-> windiff: [0.5354962497819641, 0.5125891733109526]\n",
      "-> pk: [0.4655067155067155, 0.4409987410826689]\n",
      "-> k-kappa: [0.04561136730943371, 0.08300125028904579]\n",
      "\n",
      "-> windiff - mean: 0.5240427115464583 , - var: 0.0002623670762243851\n",
      "-> pk - mean: 0.4532527282946922 , - var: 0.0003003204051848616\n",
      "-> k-kappa - mean: 0.06430630879923975 , - var: 0.0006990016746145425\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.40118611547182975, 0.39592950062945864]\n",
      "-> pk: [0.40118611547182975, 0.39592950062945864]\n",
      "-> k-kappa: [0.0, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.3985578080506442 , - var: 1.3815999800518125e-05\n",
      "-> pk - mean: 0.3985578080506442 , - var: 1.3815999800518125e-05\n",
      "-> k-kappa - mean: 0.0 , - var: 0.0\n",
      "\n",
      "\n",
      "-> Features = ['speakerChange', 'f0_diff']\n",
      "----- DT:\n",
      "-> windiff: [0.47677884823087224, 0.5125868215060086]\n",
      "-> pk: [0.4501663282498812, 0.45150858108853037]\n",
      "-> k-kappa: [0.004753208924599602, 0.049661517489607926]\n",
      "\n",
      "-> windiff - mean: 0.49468283486844045 , - var: 0.0006411054750364416\n",
      "-> pk - mean: 0.4508374546692058 , - var: 9.008213414309094e-07\n",
      "-> k-kappa - mean: 0.027207363207103763 , - var: 0.001008378089085\n",
      "\n",
      "\n",
      "----- NB:\n",
      "-> windiff: [0.41806713612995205, 0.39186358457976556]\n",
      "-> pk: [0.41461096470384934, 0.39186358457976556]\n",
      "-> k-kappa: [0.0014731907136627017, 0.0]\n",
      "\n",
      "-> windiff - mean: 0.4049653603548588 , - var: 0.0003433130569216406\n",
      "-> pk - mean: 0.4032372746418075 , - var: 0.00025872165125478096\n",
      "-> k-kappa - mean: 0.0007365953568313509 , - var: 1.0851454394110102e-06\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m NB_scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m---> 23\u001b[0m     X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m mtt\u001b[39m.\u001b[39mread_in_dataset_all_together(feature_comb,shifts,split,subtopic_lvl)        \n\u001b[0;32m     25\u001b[0m     \u001b[39m# X_train = X_train[feature_comb]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39m# X_test = X_test[feature_comb]\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     DT_scores\u001b[39m.\u001b[39mappend(get_eval(DecTree(X_train,X_test,y_train,\u001b[39mFalse\u001b[39;00m),y_test))\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:371\u001b[0m, in \u001b[0;36mread_in_dataset_all_together\u001b[1;34m(features, shifts, test_split, subtopic_lvl)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         base_y\u001b[39m.\u001b[39mappend(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 371\u001b[0m temp_df \u001b[39m=\u001b[39m transform_rows(temp_df, features, shifts)\n\u001b[0;32m    373\u001b[0m base_df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([base_df_test, temp_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    374\u001b[0m base_y_test \u001b[39m=\u001b[39m base_y_test \u001b[39m+\u001b[39m base_y\n",
      "File \u001b[1;32mc:\\Users\\marti\\Desktop\\TU Delft\\Q2\\Seminar Social Signal Processing\\code\\our code\\social-signal-processing-project\\source\\model_trainer_and_tester.py:407\u001b[0m, in \u001b[0;36mtransform_rows\u001b[1;34m(dataframe, features, shifts)\u001b[0m\n\u001b[0;32m    404\u001b[0m filtered_df \u001b[39m=\u001b[39m dataframe[features]\n\u001b[0;32m    405\u001b[0m filtered_df \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mboundary\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m temp_df \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39;49madd_suffix(\u001b[39m'\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    408\u001b[0m \u001b[39m# Doing a filter on nans, just in case\u001b[39;00m\n\u001b[0;32m    409\u001b[0m temp_df \u001b[39m=\u001b[39m handle_nas(temp_df)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4747\u001b[0m, in \u001b[0;36mNDFrame.add_suffix\u001b[1;34m(self, suffix)\u001b[0m\n\u001b[0;32m   4742\u001b[0m mapper \u001b[39m=\u001b[39m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis_name: f}\n\u001b[0;32m   4743\u001b[0m \u001b[39m# error: Incompatible return value type (got \"Optional[NDFrameT]\",\u001b[39;00m\n\u001b[0;32m   4744\u001b[0m \u001b[39m# expected \"NDFrameT\")\u001b[39;00m\n\u001b[0;32m   4745\u001b[0m \u001b[39m# error: Argument 1 to \"rename\" of \"NDFrame\" has incompatible type\u001b[39;00m\n\u001b[0;32m   4746\u001b[0m \u001b[39m# \"**Dict[str, partial[str]]\"; expected \"Union[str, int, None]\"\u001b[39;00m\n\u001b[1;32m-> 4747\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rename(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmapper)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:1076\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   1073\u001b[0m         index \u001b[39m=\u001b[39m mapper\n\u001b[0;32m   1075\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_inplace_and_allows_duplicate_labels(inplace)\n\u001b[1;32m-> 1076\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1078\u001b[0m \u001b[39mfor\u001b[39;00m axis_no, replacements \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m((index, columns)):\n\u001b[0;32m   1079\u001b[0m     \u001b[39mif\u001b[39;00m replacements \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:6373\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6263\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   6264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcopy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, deep: bool_t \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   6265\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6266\u001b[0m \u001b[39m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6267\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6371\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[0;32m   6372\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6373\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcopy(deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[0;32m   6374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcopy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:645\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[1;32m--> 645\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mcopy\u001b[39;49m\u001b[39m\"\u001b[39;49m, deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[0;32m    646\u001b[0m new_refs: \u001b[39mlist\u001b[39m[weakref\u001b[39m.\u001b[39mref \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m deep:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:348\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    347\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    349\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\blocks.py:550\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    548\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 550\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(values, placement\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr_locs, ndim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002 Bns003 Bro003 Bro004 Bro005 Bro007 Bro008 Bro010 Bro011 Bro012 Bro013 Bro014 Bro015 Bro016 Bro017 Bro018 Bro019 Bro021 Bro022 Bro023 Bro024 Bro025 Bro026 Bro027 Bro028 Bsr001 Btr001 Btr002\"\"\".split(\" \")\n",
    "results_merged_path = \"../results_merged_f0_stds_fixed/\"\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "features_selected = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "split = 0.3\n",
    "shifts = [-2, -1, 1, 2]\n",
    "subtopic_lvl = 1\n",
    "\n",
    "iterations = 2\n",
    "\n",
    "print('EXPERIMENTING ON FEATURES COMBINATIONS WITH SPLIT:',split,'(of testing), ITERATIONS:',iterations,', SHIFTS:',shifts,', AND SUBTOPIC LVL:',subtopic_lvl)\n",
    "for i in range(1,len(all_features)+1):\n",
    "    print('------ALL COMBINATIONS OF LENGTH',i,'------')\n",
    "    features_combinations = combinations(all_features,i)\n",
    "    for feature_comb in features_combinations:\n",
    "        feature_comb = list(feature_comb)\n",
    "        DT_scores = []\n",
    "        SVM_scores = []\n",
    "        NB_scores = []\n",
    "        for j in range(iterations):\n",
    "            X_train, y_train, X_test, y_test = mtt.read_in_dataset_all_together(feature_comb,shifts,split,subtopic_lvl)        \n",
    "\n",
    "            # X_train = X_train[feature_comb]\n",
    "            # X_test = X_test[feature_comb]\n",
    "            \n",
    "            DT_scores.append(get_eval(DecTree(X_train,X_test,y_train,False),y_test))\n",
    "            # SVM_scores.append(get_eval(SVM(X_train,X_test,y_train,False),y_test))\n",
    "            NB_scores.append(get_eval(naiveBayes(X_train,X_test,y_train,False),y_test))\n",
    "        \n",
    "        print('-> Features =',feature_comb)\n",
    "        print('----- DT:')\n",
    "        get_avg_eval(DT_scores)\n",
    "        print()\n",
    "        # print('----- SVM:')\n",
    "        # get_avg_eval(SVM_scores)\n",
    "        print()\n",
    "        print('----- NB:')\n",
    "        get_avg_eval(NB_scores)\n",
    "        print()\n",
    "        print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ea1fa22",
   "metadata": {},
   "source": [
    "#### To read the file of the output of the code \n",
    "Please add the file in the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e501a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.10658901085020546', '0.10266616909897681', '-0.04659279581705039', '0.029284132290540693', '0.12114758465146477', '0.05468937802760812', '-0.04198029181586795', '0.0025401207878630134', '0.1894085782008286', '0.07655725318534783']\n"
     ]
    }
   ],
   "source": [
    "path = (os.path.realpath(os.path.join(os.getcwd(), (f\"simple_models.txt\"))))\n",
    "file = open(path, 'r')\n",
    "lines = file.readlines()\n",
    "\n",
    "combination=['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff']\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    if str(combination) in lines[i]:\n",
    "        DT_windiff=lines[i+2][12:-1].strip('][').split(', ')\n",
    "        DT_pk=lines[i+3][7:-1].strip('][').split(', ')\n",
    "        DT_kappa=lines[i+4][12:-1].strip('][').split(', ')\n",
    "\n",
    "        NB_windiff=lines[i+6][12:-1].strip('][').split(', ')\n",
    "        NB_pk=lines[i+7][7:-1].strip('][').split(', ')\n",
    "        NB_kappa=lines[i+8][12:-1].strip('][').split(', ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
