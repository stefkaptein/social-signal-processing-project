{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, Input, TimeDistributed\n",
    "from model.load_data import train_test_split, train_test_split_LSTM\n",
    "\n",
    "from model.scoring_metrics import get_windiff, get_pk, get_k_kappa\n",
    "\n",
    "from model_trainer_and_tester import read_in_dataset_lstm, test_set_evaluate_multiple_lstm\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[-1, 0, 1]\n",
      "[-2, -1, 0, 1, 2]\n",
      "[-3, -2, -1, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    temp = [x for x in range(-i, i+1, 1)]\n",
    "    print(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n",
      "76/76 [==============================] - 2s 2ms/step\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "50/50 [==============================] - 0s 3ms/step\n",
      "58/58 [==============================] - 0s 3ms/step\n",
      "55/55 [==============================] - 0s 3ms/step\n",
      "52/52 [==============================] - 0s 2ms/step\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 2ms/step\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "34/34 [==============================] - 0s 2ms/step\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "44/44 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "58/58 [==============================] - 0s 2ms/step\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "45/45 [==============================] - 0s 2ms/step\n",
      "66/66 [==============================] - 0s 2ms/step\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "86/86 [==============================] - 0s 2ms/step\n",
      "Finished context size 0\n",
      "Fitting model\n",
      "76/76 [==============================] - 2s 4ms/step\n",
      "71/71 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 4ms/step\n",
      "58/58 [==============================] - 0s 4ms/step\n",
      "55/55 [==============================] - 0s 4ms/step\n",
      "52/52 [==============================] - 0s 4ms/step\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "26/26 [==============================] - 0s 3ms/step\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "34/34 [==============================] - 0s 5ms/step\n",
      "38/38 [==============================] - 0s 4ms/step\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "30/30 [==============================] - 0s 4ms/step\n",
      "42/42 [==============================] - 0s 5ms/step\n",
      "58/58 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 5ms/step\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "55/55 [==============================] - 0s 5ms/step\n",
      "45/45 [==============================] - 0s 4ms/step\n",
      "66/66 [==============================] - 0s 4ms/step\n",
      "75/75 [==============================] - 0s 5ms/step\n",
      "86/86 [==============================] - 0s 5ms/step\n",
      "Finished context size 1\n",
      "Fitting model\n",
      "76/76 [==============================] - 2s 8ms/step\n",
      "71/71 [==============================] - 1s 7ms/step\n",
      "50/50 [==============================] - 0s 7ms/step\n",
      "58/58 [==============================] - 0s 8ms/step\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "52/52 [==============================] - 0s 8ms/step\n",
      "28/28 [==============================] - 0s 8ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "40/40 [==============================] - 0s 8ms/step\n",
      "26/26 [==============================] - 0s 8ms/step\n",
      "39/39 [==============================] - 0s 9ms/step\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "34/34 [==============================] - 0s 9ms/step\n",
      "38/38 [==============================] - 0s 9ms/step\n",
      "44/44 [==============================] - 0s 9ms/step\n",
      "41/41 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 9ms/step\n",
      "30/30 [==============================] - 0s 9ms/step\n",
      "42/42 [==============================] - 0s 9ms/step\n",
      "58/58 [==============================] - 0s 8ms/step\n",
      "24/24 [==============================] - 0s 8ms/step\n",
      "41/41 [==============================] - 0s 8ms/step\n",
      "55/55 [==============================] - 0s 8ms/step\n",
      "45/45 [==============================] - 0s 9ms/step\n",
      "66/66 [==============================] - 1s 8ms/step\n",
      "75/75 [==============================] - 1s 8ms/step\n",
      "86/86 [==============================] - 1s 8ms/step\n",
      "Finished context size 2\n",
      "Fitting model\n",
      "76/76 [==============================] - 2s 9ms/step\n",
      "71/71 [==============================] - 1s 9ms/step\n",
      "50/50 [==============================] - 0s 9ms/step\n",
      "58/58 [==============================] - 1s 9ms/step\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      "52/52 [==============================] - 1s 9ms/step\n",
      "28/28 [==============================] - 0s 10ms/step\n",
      "18/18 [==============================] - 0s 10ms/step\n",
      "32/32 [==============================] - 0s 10ms/step\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "26/26 [==============================] - 0s 10ms/step\n",
      "39/39 [==============================] - 0s 10ms/step\n",
      "8/8 [==============================] - 0s 10ms/step\n",
      "34/34 [==============================] - 0s 10ms/step\n",
      "38/38 [==============================] - 0s 10ms/step\n",
      "44/44 [==============================] - 0s 10ms/step\n",
      "41/41 [==============================] - 0s 10ms/step\n",
      "36/36 [==============================] - 0s 10ms/step\n",
      "30/30 [==============================] - 0s 10ms/step\n",
      "42/42 [==============================] - 0s 10ms/step\n",
      "58/58 [==============================] - 1s 9ms/step\n",
      "24/24 [==============================] - 0s 9ms/step\n",
      "41/41 [==============================] - 0s 9ms/step\n",
      "55/55 [==============================] - 1s 9ms/step\n",
      "45/45 [==============================] - 0s 9ms/step\n",
      "66/66 [==============================] - 1s 10ms/step\n",
      "75/75 [==============================] - 1s 9ms/step\n",
      "86/86 [==============================] - 1s 10ms/step\n",
      "Finished context size 3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# I optimize on this, I think?\n",
    "LSTM_units = 20\n",
    "\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff', 'f0_stds_means']\n",
    "\n",
    "# Some of the features aren't really relevant, so I'll just go ahead and ignore them\n",
    "# It's mainly the segID and the start and end times\n",
    "all_features = ['pause', 'speakerChange', 'similarity', 'f0_diff', 'f0_baseline_diff', 'f0_stds_means']\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "# These are parameters that are constant regardless of the model\n",
    "batch_size = 64\n",
    "shifts = [-2, -1, 0, 1, 2]\n",
    "hidden_units = 100\n",
    "\n",
    "for i in range(4):\n",
    "    shifts = [x for x in range(-i, i+1, 1)]\n",
    "    temp_features = all_features\n",
    "\n",
    "    n_timesteps = len(shifts)\n",
    "    feature_count = len(temp_features)\n",
    "\n",
    "    X_train, Y_train = read_in_dataset_lstm(temp_features, shifts, to_read='train')\n",
    "\n",
    "    sample_weight = np.ones(shape=(len(Y_train),))\n",
    "    # I'm gonna increase the weight by the inverse of the proportion of weird examples that there are\n",
    "    # How I define if there is a weird sample is by summing along the 2D squares to find where there's a 1, and then does a sum of times there's a 1\n",
    "    # I'm going to do n_timesteps times the inverse count frequency, because in the final version we only predict with the center value. So to correct for this I add this increase\n",
    "    new_weight = n_timesteps*len(Y_train)/np.sum(Y_train, axis=1).sum()\n",
    "\n",
    "    # Have to do a flatten() inside because of weird numpy stuff with a length 1 dimension\n",
    "    sample_weight[(np.sum(Y_train, axis=1) >= 1).flatten()] = new_weight\n",
    "\n",
    "    model = Sequential()\n",
    "    # For the input number of units, I'll assume that number of timesteps * features is a good enough value\n",
    "    model.add(Bidirectional(LSTM(hidden_units, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "    model.add(Bidirectional(LSTM(hidden_units, activation='tanh', return_sequences=True, dropout=0.3), input_shape=(n_timesteps, feature_count)))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(hidden_units, activation='sigmoid', return_sequences=True, dropout=0.3)))\n",
    "    # This last time distributed is super important, it follows the output structure of the paper I've been following closely\n",
    "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "    import tensorflow_addons as tfa\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop',\n",
    "                  metrics=[keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')],\n",
    "                  weighted_metrics=[]\n",
    "                  )\n",
    "\n",
    "    # train the model\n",
    "    print('Fitting model')\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=20,\n",
    "                        #class_weight= {0:1, 1:10},\n",
    "                        # sample_weight_mode='temporal',\n",
    "                        sample_weight=sample_weight,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=0\n",
    "                        )\n",
    "\n",
    "    temp_results = test_set_evaluate_multiple_lstm(model, temp_features, shifts)\n",
    "\n",
    "    results_dict[i] = pd.concat([temp_results.mean().add_suffix('_mean'), temp_results.std().add_suffix('_std')])\n",
    "    print(\"Finished context size \" + str(i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_csv('BLSTM_context_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
