{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)\n",
    "from sklearn.feature_selection import RFECV\n",
    "import random\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First part is merging all meetings\n",
    "datasets = \"\"\"Bed002 Bed003 Bed004 Bed005 Bed006 Bed008 Bed009 Bed010 Bed011 Bed012 Bed013 Bed014 Bed015 Bed016 Bed017 Bmr001 Bmr002 Bmr005 Bmr007 Bmr009 Bmr010 Bmr011 Bmr012 Bmr013 Bmr014 Bmr018 Bmr019 Bmr021 Bmr022 Bmr024 Bmr025 Bmr026 Bmr027 Bmr029 Bns001 Bns002\"\"\".split(\" \")\n",
    "results_merged_path = \"../social-signal-processing-project/results_merged/\"\n",
    "\n",
    "all_df = pd.DataFrame()\n",
    "for elem in datasets:\n",
    "    path = (os.path.realpath(os.path.join(os.getcwd(), (f\"{results_merged_path}\"+ elem + \".csv\"))))\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "    all_df = pd.concat([all_df,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    916.000000\n",
      "mean       0.500000\n",
      "std        0.500273\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.500000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: boundary, dtype: float64\n",
      "StartTimeA       0.549669\n",
      "EndTimeA         0.550042\n",
      "StartTimeB       0.549596\n",
      "EndTimeB         0.549842\n",
      "pause            0.065577\n",
      "speakerChange    0.376063\n",
      "dtype: float64\n",
      "StartTimeA       5.790\n",
      "EndTimeA         6.200\n",
      "StartTimeB       6.393\n",
      "EndTimeB         7.043\n",
      "pause            0.193\n",
      "speakerChange    1.000\n",
      "Name: 0, dtype: float64\n",
      "        StartTimeA     EndTimeA   StartTimeB     EndTimeB       pause  \\\n",
      "count   916.000000   915.000000   916.000000   916.000000  915.000000   \n",
      "mean   1082.017647  1084.349883  1084.598391  1087.256819    0.611268   \n",
      "std     951.011860   951.741243   951.225975   951.402978    3.475570   \n",
      "min       5.790000     6.200000     6.393000     7.043000  -85.570000   \n",
      "25%     385.637250   386.212000   388.264750   389.549750    0.000000   \n",
      "50%     819.589000   826.394000   825.507000   827.519000    0.470000   \n",
      "75%    1468.537500  1473.594500  1473.929750  1477.762250    1.007000   \n",
      "max    6011.183000  6012.638000  6013.810000  6026.360000   20.165000   \n",
      "\n",
      "       speakerChange  \n",
      "count     916.000000  \n",
      "mean        0.473799  \n",
      "std         0.499586  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         1.000000  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "#change boolean to 1 or 0\n",
    "all_df['speakerChange'] = all_df[\"speakerChange\"].astype(float)\n",
    "all_df['boundary'] = all_df[\"boundary\"].astype(float)\n",
    "\n",
    "#keep only useful columns (can't use f0_means, f0_stds, and similarity yet as they are lists)\n",
    "#normal split (but WARNING!!! NBR OF BOUNDARY == 1 IS VERYYYY LOW)\n",
    "# X_df = all_df[['StartTimeA','EndTimeA','StartTimeB','EndTimeB','pause','speakerChange']]\n",
    "# y_df = all_df['boundary']\n",
    "\n",
    "#test using the same amount of rows with boundary==1 and ==0\n",
    "nbr_1 = len(all_df.loc[all_df['boundary']==1])\n",
    "df_0 = all_df.loc[all_df['boundary']==0].head(nbr_1)\n",
    "df_1 = all_df.loc[all_df['boundary']==1]\n",
    "df_balanced = pd.concat([df_0,df_1], ignore_index=True)\n",
    "df_balanced.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_df = df_balanced[['StartTimeA','EndTimeA','StartTimeB','EndTimeB','pause','speakerChange']]\n",
    "y_df = df_balanced['boundary']\n",
    "\n",
    "#check dataset statistics\n",
    "print(y_df.describe())\n",
    "print(X_df.corrwith(y_df))\n",
    "print(X_df.loc[0])\n",
    "print(X_df.describe())\n",
    "\n",
    "#split dataset\n",
    "X_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(X_df, y_df, test_size = 0.20, random_state = 97,stratify=y_df)\n",
    "X_train_40, X_test_40, y_train_40, y_test_40 = train_test_split(X_df, y_df, test_size = 0.40, random_state = 97,stratify=y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_class(X_train, X_test, y_train, y_test,learning_rate, n_estimators, max_depth,min_child_weight, gamma, subsample, colsample_bytree, simple):\n",
    "    \n",
    "    if simple:\n",
    "        clf = xgb.XGBClassifier(seed = 24, use_label_encoder =False)\n",
    "    else:\n",
    "        clf = xgb.XGBClassifier(learning_rate = learning_rate, n_estimators = int(n_estimators), max_depth = int(max_depth), \n",
    "                                min_child_weight = min_child_weight, gamma = gamma, subsample = subsample, \n",
    "                                colsample_bytree = colsample_bytree, seed = 24,eval_metric='mlogloss',use_label_encoder =False)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "    print(\"MCC =\",matthews_corrcoef(y_test, y_predicted))\n",
    "    print(\"AUC =\",metrics.roc_auc_score(y_test, y_predicted))\n",
    "    \n",
    "    return clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "C:\\Users\\marti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.89      0.87        92\n",
      "         1.0       0.89      0.84      0.86        92\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.87      0.86      0.86       184\n",
      "weighted avg       0.87      0.86      0.86       184\n",
      "\n",
      "Accuracy: 0.8641304347826086\n",
      "MCC = 0.7293387850622899\n",
      "AUC = 0.8641304347826086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.88      0.86       184\n",
      "         1.0       0.87      0.83      0.85       183\n",
      "\n",
      "    accuracy                           0.85       367\n",
      "   macro avg       0.85      0.85      0.85       367\n",
      "weighted avg       0.85      0.85      0.85       367\n",
      "\n",
      "Accuracy: 0.8528610354223434\n",
      "MCC = 0.7067267096157344\n",
      "AUC = 0.8527856973152768\n"
     ]
    }
   ],
   "source": [
    "XGBc_y_predicted_20 = XGB_class(X_train_20,X_test_20,y_train_20,y_test_20,0,0,0,0,0,0,0,simple=True)\n",
    "XGBc_y_predicted_40 = XGB_class(X_train_40,X_test_40,y_train_40,y_test_40,0,0,0,0,0,0,0,simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05509883 0.38894403 0.9987674  0.6440127  0.99681515 0.12353405\n",
      " 0.01630569 0.01630569 0.9647402  0.99681515 0.09274486 0.06772611\n",
      " 0.15069826 0.04608585 0.99826366 0.082968   0.6746042  0.9988558\n",
      " 0.6096827  0.87642014 0.12205827 0.01664189 0.18968563 0.00845762\n",
      " 0.30182478 0.989597   0.27458394 0.9987674  0.9988079  0.40125638\n",
      " 0.19205125 0.9958319  0.10581758 0.06121317 0.9959317  0.02677582\n",
      " 0.99668854 0.99894637 0.9814108  0.02357747 0.16976742 0.12406015\n",
      " 0.4666691  0.9987674  0.9988244  0.6266333  0.9940625  0.9976659\n",
      " 0.09737234 0.00845762 0.12415402 0.99799675 0.9982653  0.02676754\n",
      " 0.02863378 0.6888694  0.28424534 0.21916924 0.99799675 0.01630569\n",
      " 0.01630569 0.28835917 0.04327187 0.02714457 0.9985638  0.0164698\n",
      " 0.00276963 0.26400766 0.9978752  0.99317545 0.91990054 0.10171605\n",
      " 0.9945886  0.01365484 0.99799675 0.38817155 0.66258454 0.13520667\n",
      " 0.4476232  0.1153617  0.9989084  0.03721153 0.44371867 0.99862945\n",
      " 0.9969432  0.27310315 0.9959085  0.01004513 0.55192447 0.78597903\n",
      " 0.47451118 0.00565864 0.02271195 0.8794473  0.60211885 0.99843043\n",
      " 0.00495681 0.99727684 0.07096152 0.99884915 0.9531118  0.9985758\n",
      " 0.3405657  0.02792393 0.99896526 0.9935411  0.99894637 0.9935622\n",
      " 0.99668854 0.05561363 0.68151534 0.01203982 0.4589697  0.923972\n",
      " 0.02303376 0.99894637 0.4685503  0.99843043 0.993903   0.12500761\n",
      " 0.6876705  0.31034917 0.99843043 0.0094389  0.99774325 0.36559775\n",
      " 0.05622762 0.9974432  0.71731716 0.9980313  0.6914876  0.11346975\n",
      " 0.17037593 0.15680343 0.01423038 0.14518699 0.99843043 0.3691664\n",
      " 0.9987674  0.10213418 0.02528957 0.99843043 0.02495521 0.99843043\n",
      " 0.20666535 0.16350351 0.05731637 0.989597   0.99821043 0.9935411\n",
      " 0.10175233 0.9988243  0.00194226 0.55148995 0.11790372 0.97987205\n",
      " 0.3290543  0.9424504  0.9975611  0.99896526 0.9991171  0.12840503\n",
      " 0.9978752  0.11313172 0.06218253 0.10543987 0.37739527 0.4749922\n",
      " 0.98340535 0.9990355  0.07217815 0.99843043 0.99757737 0.6391996\n",
      " 0.9923483  0.01087017 0.06122642 0.00652845 0.9058872  0.02214438\n",
      " 0.14681578 0.01927565 0.9985758  0.33101955]\n"
     ]
    }
   ],
   "source": [
    "print(XGBc_y_predicted_20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "951acce4ee2d6eb9fe3565b96e466293146d7f1585a7e067fb08e2ff6ef89eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
